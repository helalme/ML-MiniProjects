{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"03 BelgianTrafficSignalClassification.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"dWPqdf9N0Oj1","colab_type":"text"},"source":["## 0.0 **Belgian Traffic Signs Classification:** \n","\n","This notebook shows step by step how to achieve upto **99% validation accuracy** with BelgianTS dataset using convolutional neural network.\n","\n","#### **Dataset:**\n","The dataset of BelgianTS is wellknown and probably it has [various versions](https://btsd.ethz.ch/shareddata/)  with different sizes. The dataset used here contains 62 classes of images, with 4575 images (227 MB) for training and 2520 for validation (105 MB).\n","\n","#### **Models applied:**\n","The notebook starts with a very simple feed-forward NN with just two layers claiming 93.8% validation accuracy. Then different layers (Conv2D, Pooling, Dropuout etc.) have been added step by step to increase the accuracy on the validation set. Different image augmentation techniques have also has been attempted like flipping, rotation, random-zoom etc. At the end transfer learning has been applied with models from TensorFlow Hub. \n","\n","#### **Images resolution, model complexity and the accuracy:** \n","The training dataset has not been gone through any preprocessig, rather originl images have been used. The resolution of the images has been kept as low as possible. The resolution of 28-28-3 has been used for most cases, at the end 56-56-3 has also been used in order to see whether they can achieve higher accuracy than that of lower resolution images. The beuaty of low resolution images is that it deos not take longer time for training and very simple NN model can give convincing accuracy. At the beginning light-weight models have been attempted with lower resolution images. Grey scale images results in faster training, whereas RGB images give higher accuracy. Training with grey-images has been shown once. However high resolution images cause higher training time and need more complex model, and gives  better accuracy once the model is fine tuned.\n","\n","   "]},{"cell_type":"markdown","metadata":{"id":"XXsq4_ZE977o","colab_type":"text"},"source":["#### 0.1 Necessary modules and packages"]},{"cell_type":"code","metadata":{"id":"1t3jVWXfzR9n","colab_type":"code","colab":{}},"source":["import os\n","#from skimage import data\n","import imageio\n","#from skimage.viewer import ImageViewer\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","from skimage import transform\n","from skimage.color import rgb2gray\n","import tensorflow_hub as hub"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8G1duNPf68mT","colab_type":"text"},"source":["### 0.2 Below few cells are related to ETL process of data preprocessing "]},{"cell_type":"markdown","metadata":{"id":"4wS3t4Do-R-l","colab_type":"text"},"source":["#### 0.2.1 Mounting google drive"]},{"cell_type":"code","metadata":{"id":"koAQMsX2z3RP","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NaDd9re3-Kgm","colab_type":"text"},"source":["#### 0.2.2 Function for loading images"]},{"cell_type":"code","metadata":{"id":"UJDX4PBFzR-I","colab_type":"code","colab":{}},"source":["def load_data(data_directory):\n","    directories = [d for d in os.listdir(data_directory) \n","                   if os.path.isdir(os.path.join(data_directory, d))]\n","    labels = []\n","    images = []\n","    for d in directories:\n","        label_directory = os.path.join(data_directory, d)\n","        file_names = [os.path.join(label_directory, f) \n","                      for f in os.listdir(label_directory) \n","                      if f.endswith(\".ppm\")]\n","        for f in file_names:\n","            images.append(imageio.imread(f)) #skimage theke data import kore imread() call kora hoise \n","            labels.append(int(d))\n","    return images, labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-LU38zLzLvEE","colab_type":"text"},"source":["#### 0.2.3 Loading images"]},{"cell_type":"code","metadata":{"id":"HJgfo6EAzR-Z","colab_type":"code","colab":{}},"source":["#cwd = os.getcwd()\n","cwd = \"/content/drive/My Drive/DL-practice/TrafficSigns\"\n","train_data_directory = os.path.join(cwd, \"Training\")\n","test_data_directory = os.path.join(cwd, \"Testing\")\n","\n","x_train, y_train = load_data(train_data_directory)\n","x_test, y_test = load_data(test_data_directory)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nj86h1of-msK","colab_type":"text"},"source":["#### 0.3.1 training and validation images with 28-28-3 resolution + Gray images"]},{"cell_type":"code","metadata":{"id":"qWQzNCuuzR_k","colab_type":"code","colab":{}},"source":["Trainingimages28 = [transform.resize(image, (28, 28)) for image in x_train]\n","Trainingimages28 = np.array(Trainingimages28)\n","Trainingimages28gray = rgb2gray(Trainingimages28)\n","\n","Testimages28 = [transform.resize(image, (28, 28)) for image in x_test]\n","Testimages28 = np.array(Testimages28)\n","Testimages28gray = rgb2gray(Testimages28)\n","\n","y_train = np.array(y_train)\n","y_test = np.array(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tKTMqFqp_QpT","colab_type":"text"},"source":["#### 0.3.2 Generating training and validation images with 56-56-3 resolution + Gray images"]},{"cell_type":"code","metadata":{"id":"2VgyygEDzR-k","colab_type":"code","colab":{}},"source":["Trainingimages56 = [transform.resize(image, (56, 56)) for image in x_train]\n","Trainingimages56 = np.array(Trainingimages56)\n","#Trainimages56gray = rgb2gray(Trainingimages56)\n","\n","Testimages56 = [transform.resize(image, (56, 56)) for image in x_test]\n","Testimages56 = np.array(Testimages56)\n","#Testimages56 = rgb2gray(Testimages56)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SXAKa0tT_vAq","colab_type":"text"},"source":["#### 0.3.3 Generating training and validation images with 112-112-3 resolution\n","\n"]},{"cell_type":"code","metadata":{"id":"C_9cgqFY_fEQ","colab_type":"code","colab":{}},"source":["Trainingimages112 = [transform.resize(image, (112, 112)) for image in x_train]\n","Trainingimages112 = np.array(Trainingimages112)\n","\n","Testimages112 = [transform.resize(image, (112, 112)) for image in x_test]\n","Testimages112 = np.array(Testimages112)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fV7aRUxTCOL8","colab_type":"text"},"source":["#### 1.0 At first, check the learning rate whether the default one (0.001) of the Adam optimizer is the right one"]},{"cell_type":"code","metadata":{"id":"E1poZDUxAmco","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597997048147,"user_tz":-120,"elapsed":46977,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"80e4ea02-68b8-4ca4-d0d5-d6a70c43d1f2"},"source":["model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28,3)),\n","  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n","\n","])\n","\n","opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-6 * 10**(epoch / 20))\n","\n","history = model.fit(Trainingimages28, y_train, validation_data=(Testimages28, y_test), \n","          epochs=100, callbacks=[lr_schedule])\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","143/143 [==============================] - 1s 4ms/step - loss: 4.3885 - accuracy: 0.0129 - val_loss: 4.3696 - val_accuracy: 0.0056\n","Epoch 2/100\n","143/143 [==============================] - 0s 3ms/step - loss: 4.2216 - accuracy: 0.0210 - val_loss: 4.2267 - val_accuracy: 0.0060\n","Epoch 3/100\n","143/143 [==============================] - 0s 3ms/step - loss: 4.0686 - accuracy: 0.0553 - val_loss: 4.0917 - val_accuracy: 0.0230\n","Epoch 4/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.9326 - accuracy: 0.0929 - val_loss: 3.9695 - val_accuracy: 0.0425\n","Epoch 5/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.8143 - accuracy: 0.1189 - val_loss: 3.8559 - val_accuracy: 0.0984\n","Epoch 6/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.7115 - accuracy: 0.1532 - val_loss: 3.7563 - val_accuracy: 0.1599\n","Epoch 7/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.6202 - accuracy: 0.1919 - val_loss: 3.6646 - val_accuracy: 0.2230\n","Epoch 8/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.5338 - accuracy: 0.2256 - val_loss: 3.5853 - val_accuracy: 0.2651\n","Epoch 9/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.4527 - accuracy: 0.2586 - val_loss: 3.5142 - val_accuracy: 0.2956\n","Epoch 10/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.3742 - accuracy: 0.2798 - val_loss: 3.4437 - val_accuracy: 0.3258\n","Epoch 11/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.2965 - accuracy: 0.3095 - val_loss: 3.3672 - val_accuracy: 0.3552\n","Epoch 12/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.2174 - accuracy: 0.3351 - val_loss: 3.2872 - val_accuracy: 0.3706\n","Epoch 13/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.1352 - accuracy: 0.3626 - val_loss: 3.2066 - val_accuracy: 0.3778\n","Epoch 14/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.0504 - accuracy: 0.3792 - val_loss: 3.1242 - val_accuracy: 0.3921\n","Epoch 15/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.9606 - accuracy: 0.4063 - val_loss: 3.0207 - val_accuracy: 0.4056\n","Epoch 16/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.8647 - accuracy: 0.4238 - val_loss: 2.9293 - val_accuracy: 0.4222\n","Epoch 17/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.7668 - accuracy: 0.4509 - val_loss: 2.8283 - val_accuracy: 0.4333\n","Epoch 18/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.6698 - accuracy: 0.4612 - val_loss: 2.7479 - val_accuracy: 0.4425\n","Epoch 19/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.5714 - accuracy: 0.4857 - val_loss: 2.6462 - val_accuracy: 0.4607\n","Epoch 20/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.4740 - accuracy: 0.5012 - val_loss: 2.5659 - val_accuracy: 0.4786\n","Epoch 21/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.3744 - accuracy: 0.5217 - val_loss: 2.4833 - val_accuracy: 0.4948\n","Epoch 22/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.2759 - accuracy: 0.5484 - val_loss: 2.3794 - val_accuracy: 0.5139\n","Epoch 23/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.1756 - accuracy: 0.5711 - val_loss: 2.2952 - val_accuracy: 0.5179\n","Epoch 24/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.0755 - accuracy: 0.5891 - val_loss: 2.1930 - val_accuracy: 0.5329\n","Epoch 25/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.9735 - accuracy: 0.6125 - val_loss: 2.0982 - val_accuracy: 0.5508\n","Epoch 26/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.8754 - accuracy: 0.6299 - val_loss: 2.0070 - val_accuracy: 0.5611\n","Epoch 27/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.7786 - accuracy: 0.6568 - val_loss: 1.9020 - val_accuracy: 0.5897\n","Epoch 28/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.6801 - accuracy: 0.6706 - val_loss: 1.8194 - val_accuracy: 0.5833\n","Epoch 29/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.5845 - accuracy: 0.6879 - val_loss: 1.7099 - val_accuracy: 0.6290\n","Epoch 30/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.4879 - accuracy: 0.7064 - val_loss: 1.6229 - val_accuracy: 0.6607\n","Epoch 31/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.3941 - accuracy: 0.7311 - val_loss: 1.5339 - val_accuracy: 0.6381\n","Epoch 32/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.3048 - accuracy: 0.7469 - val_loss: 1.4552 - val_accuracy: 0.7155\n","Epoch 33/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.2177 - accuracy: 0.7692 - val_loss: 1.3412 - val_accuracy: 0.7329\n","Epoch 34/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.1315 - accuracy: 0.7930 - val_loss: 1.2659 - val_accuracy: 0.7286\n","Epoch 35/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.0507 - accuracy: 0.8120 - val_loss: 1.2363 - val_accuracy: 0.7456\n","Epoch 36/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.9720 - accuracy: 0.8293 - val_loss: 1.1411 - val_accuracy: 0.7730\n","Epoch 37/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.8968 - accuracy: 0.8400 - val_loss: 1.1007 - val_accuracy: 0.7782\n","Epoch 38/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.8218 - accuracy: 0.8573 - val_loss: 0.9785 - val_accuracy: 0.8075\n","Epoch 39/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.7541 - accuracy: 0.8678 - val_loss: 0.9473 - val_accuracy: 0.8040\n","Epoch 40/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.8798 - val_loss: 0.8981 - val_accuracy: 0.8107\n","Epoch 41/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.8894 - val_loss: 0.8168 - val_accuracy: 0.8262\n","Epoch 42/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.9030 - val_loss: 0.7408 - val_accuracy: 0.8480\n","Epoch 43/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.9134 - val_loss: 0.7310 - val_accuracy: 0.8409\n","Epoch 44/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.9220 - val_loss: 0.6663 - val_accuracy: 0.8567\n","Epoch 45/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.9266 - val_loss: 0.6114 - val_accuracy: 0.8563\n","Epoch 46/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.9379 - val_loss: 0.5794 - val_accuracy: 0.8647\n","Epoch 47/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.9438 - val_loss: 0.5487 - val_accuracy: 0.8687\n","Epoch 48/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.9552 - val_loss: 0.6406 - val_accuracy: 0.8230\n","Epoch 49/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.9545 - val_loss: 0.4996 - val_accuracy: 0.8718\n","Epoch 50/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.9633 - val_loss: 0.4824 - val_accuracy: 0.8790\n","Epoch 51/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.9598 - val_loss: 0.4653 - val_accuracy: 0.8766\n","Epoch 52/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9644 - val_loss: 0.4976 - val_accuracy: 0.8563\n","Epoch 53/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9631 - val_loss: 0.4803 - val_accuracy: 0.8710\n","Epoch 54/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1899 - accuracy: 0.9620 - val_loss: 0.5927 - val_accuracy: 0.8567\n","Epoch 55/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9585 - val_loss: 0.6141 - val_accuracy: 0.8159\n","Epoch 56/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9607 - val_loss: 0.5950 - val_accuracy: 0.8413\n","Epoch 57/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9602 - val_loss: 0.5228 - val_accuracy: 0.8635\n","Epoch 58/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1414 - accuracy: 0.9681 - val_loss: 0.6679 - val_accuracy: 0.8060\n","Epoch 59/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9766 - val_loss: 0.4129 - val_accuracy: 0.8905\n","Epoch 60/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.9277 - val_loss: 0.7999 - val_accuracy: 0.8048\n","Epoch 61/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.9296 - val_loss: 0.5201 - val_accuracy: 0.8659\n","Epoch 62/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9523 - val_loss: 0.6417 - val_accuracy: 0.8413\n","Epoch 63/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.9128 - val_loss: 0.5988 - val_accuracy: 0.8516\n","Epoch 64/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.9204 - val_loss: 0.7183 - val_accuracy: 0.8202\n","Epoch 65/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.9303 - val_loss: 0.8022 - val_accuracy: 0.8159\n","Epoch 66/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9373 - val_loss: 0.6431 - val_accuracy: 0.8456\n","Epoch 67/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.9073 - val_loss: 0.7477 - val_accuracy: 0.8294\n","Epoch 68/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.9215 - val_loss: 0.8070 - val_accuracy: 0.7881\n","Epoch 69/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.9224 - val_loss: 0.7819 - val_accuracy: 0.8226\n","Epoch 70/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.9156 - val_loss: 0.9324 - val_accuracy: 0.8135\n","Epoch 71/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.9064 - val_loss: 1.4338 - val_accuracy: 0.7944\n","Epoch 72/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.8605 - val_loss: 1.0225 - val_accuracy: 0.7845\n","Epoch 73/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8750 - val_loss: 0.9128 - val_accuracy: 0.7500\n","Epoch 74/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8787 - val_loss: 0.6427 - val_accuracy: 0.8468\n","Epoch 75/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8909 - val_loss: 0.6588 - val_accuracy: 0.8317\n","Epoch 76/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.8511 - val_loss: 0.7120 - val_accuracy: 0.8302\n","Epoch 77/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.8710 - val_loss: 1.2947 - val_accuracy: 0.7119\n","Epoch 78/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.8323 - val_loss: 0.8218 - val_accuracy: 0.8063\n","Epoch 79/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.8461 - accuracy: 0.7923 - val_loss: 1.0119 - val_accuracy: 0.7702\n","Epoch 80/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.7252 - accuracy: 0.8153 - val_loss: 0.7079 - val_accuracy: 0.8254\n","Epoch 81/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.7868 - accuracy: 0.7987 - val_loss: 1.4504 - val_accuracy: 0.6774\n","Epoch 82/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.0581 - accuracy: 0.7565 - val_loss: 1.0902 - val_accuracy: 0.7480\n","Epoch 83/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.0795 - accuracy: 0.7349 - val_loss: 1.6394 - val_accuracy: 0.6381\n","Epoch 84/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.9147 - accuracy: 0.7790 - val_loss: 1.7337 - val_accuracy: 0.5944\n","Epoch 85/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.4173 - accuracy: 0.6776 - val_loss: 1.5734 - val_accuracy: 0.6337\n","Epoch 86/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.6143 - accuracy: 0.6192 - val_loss: 1.8311 - val_accuracy: 0.5706\n","Epoch 87/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.8646 - accuracy: 0.5318 - val_loss: 1.9119 - val_accuracy: 0.5694\n","Epoch 88/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.7953 - accuracy: 0.5523 - val_loss: 1.3275 - val_accuracy: 0.6020\n","Epoch 89/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.9148 - accuracy: 0.5252 - val_loss: 2.6718 - val_accuracy: 0.2714\n","Epoch 90/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.3721 - accuracy: 0.3989 - val_loss: 2.0300 - val_accuracy: 0.5036\n","Epoch 91/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.8979 - accuracy: 0.2960 - val_loss: 3.5403 - val_accuracy: 0.1655\n","Epoch 92/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.0434 - accuracy: 0.2496 - val_loss: 2.9980 - val_accuracy: 0.4282\n","Epoch 93/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.8445 - accuracy: 0.2883 - val_loss: 2.6975 - val_accuracy: 0.3718\n","Epoch 94/100\n","143/143 [==============================] - 0s 3ms/step - loss: 2.9136 - accuracy: 0.2826 - val_loss: 2.7163 - val_accuracy: 0.3591\n","Epoch 95/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.1261 - accuracy: 0.2514 - val_loss: 3.1062 - val_accuracy: 0.2968\n","Epoch 96/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.4616 - accuracy: 0.1856 - val_loss: 3.2963 - val_accuracy: 0.2484\n","Epoch 97/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.3263 - accuracy: 0.1644 - val_loss: 3.4980 - val_accuracy: 0.1083\n","Epoch 98/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.5330 - accuracy: 0.1272 - val_loss: 3.5846 - val_accuracy: 0.0425\n","Epoch 99/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.6301 - accuracy: 0.0748 - val_loss: 3.6593 - val_accuracy: 0.0250\n","Epoch 100/100\n","143/143 [==============================] - 0s 3ms/step - loss: 3.6287 - accuracy: 0.0811 - val_loss: 3.6311 - val_accuracy: 0.0861\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hXcpv05PC3sA","colab_type":"text"},"source":["#### 1.0.1 Visualize the learning rate and choose the best one, it seems $8.0 \\times 10^{-4}$ would be the best one for this model. Since this rate is very close to the default learning rate (0.001), we will keep the default one for the rest of all models"]},{"cell_type":"code","metadata":{"id":"tK2Z07yWC1E9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":290},"executionInfo":{"status":"ok","timestamp":1597997068015,"user_tz":-120,"elapsed":1198,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"a28fb6ae-0438-439b-9430-96775d0dbb09"},"source":["plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n","plt.axis([1e-6, 1e-1, 0, 5])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1e-06, 0.1, 0.0, 5.0)"]},"metadata":{"tags":[]},"execution_count":13},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"vBvC3sqxJwve","colab_type":"text"},"source":["#### 1.1 A myCallback class for setting the stopping criteria after reaching the expected accuracy level"]},{"cell_type":"code","metadata":{"id":"1UQSpx-lJ8E2","colab_type":"code","colab":{}},"source":["class myCallback(tf.keras.callbacks.Callback):\n","  def __init__(self, expAccuracy):\n","        self.exp_Accuracy = expAccuracy\n","\n","  def on_epoch_end(self, epoch, logs={} ):\n","    if(logs.get('val_accuracy')>self.exp_Accuracy):\n","      print(\"\\nReached at the expected accuracy level on the validation set, so cancelling training!\")\n","      self.model.stop_training = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cmz2LtBQKmqL","colab_type":"text"},"source":["#### 1.2 A very simple model (with two Dense layers), Images resolution 28-28-3, validation accuracy = 93.9%. Let's say it the base model"]},{"cell_type":"code","metadata":{"id":"5XWVxZMKFSz6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598000449228,"user_tz":-120,"elapsed":22828,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"bfa1879e-126a-457b-a64d-acef02a9f2ad"},"source":["model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28,3)),\n","  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n","\n","])\n","\n","callbacks = myCallback(0.938) # Stops training after reaching 93.8% validation accuracy \n","#opt = tf.keras.optimizers.Adam(learning_rate=0.0008)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(Trainingimages28, y_train, validation_data=(Testimages28, y_test), \n","          epochs=100, callbacks=[callbacks])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","143/143 [==============================] - 1s 4ms/step - loss: 2.1970 - accuracy: 0.5204 - val_loss: 1.4886 - val_accuracy: 0.6722\n","Epoch 2/100\n","143/143 [==============================] - 0s 3ms/step - loss: 1.0849 - accuracy: 0.7600 - val_loss: 1.0721 - val_accuracy: 0.7460\n","Epoch 3/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.8247 - val_loss: 0.7112 - val_accuracy: 0.8310\n","Epoch 4/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.8774 - val_loss: 0.5766 - val_accuracy: 0.8762\n","Epoch 5/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.9123 - val_loss: 0.6546 - val_accuracy: 0.8171\n","Epoch 6/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.9239 - val_loss: 0.5222 - val_accuracy: 0.8571\n","Epoch 7/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2824 - accuracy: 0.9414 - val_loss: 0.4606 - val_accuracy: 0.8722\n","Epoch 8/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9543 - val_loss: 0.4701 - val_accuracy: 0.8750\n","Epoch 9/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9543 - val_loss: 0.4767 - val_accuracy: 0.8702\n","Epoch 10/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9687 - val_loss: 0.4125 - val_accuracy: 0.8940\n","Epoch 11/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9714 - val_loss: 0.4897 - val_accuracy: 0.8694\n","Epoch 12/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1232 - accuracy: 0.9733 - val_loss: 0.6191 - val_accuracy: 0.8230\n","Epoch 13/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9677 - val_loss: 0.4091 - val_accuracy: 0.8829\n","Epoch 14/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9779 - val_loss: 0.3887 - val_accuracy: 0.8937\n","Epoch 15/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0827 - accuracy: 0.9814 - val_loss: 0.3565 - val_accuracy: 0.9107\n","Epoch 16/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0835 - accuracy: 0.9847 - val_loss: 0.4210 - val_accuracy: 0.9024\n","Epoch 17/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9812 - val_loss: 0.3809 - val_accuracy: 0.9044\n","Epoch 18/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9757 - val_loss: 0.3940 - val_accuracy: 0.8992\n","Epoch 19/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9884 - val_loss: 0.3882 - val_accuracy: 0.8996\n","Epoch 20/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9878 - val_loss: 0.4007 - val_accuracy: 0.8877\n","Epoch 21/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9891 - val_loss: 0.4063 - val_accuracy: 0.8940\n","Epoch 22/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9878 - val_loss: 0.3628 - val_accuracy: 0.9087\n","Epoch 23/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9915 - val_loss: 0.3796 - val_accuracy: 0.9063\n","Epoch 24/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9965 - val_loss: 0.3522 - val_accuracy: 0.9163\n","Epoch 25/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9895 - val_loss: 0.4618 - val_accuracy: 0.8790\n","Epoch 26/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9945 - val_loss: 0.3366 - val_accuracy: 0.9179\n","Epoch 27/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9983 - val_loss: 0.3354 - val_accuracy: 0.9202\n","Epoch 28/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9987 - val_loss: 0.3205 - val_accuracy: 0.9242\n","Epoch 29/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9661 - val_loss: 0.7697 - val_accuracy: 0.8246\n","Epoch 30/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9773 - val_loss: 0.6370 - val_accuracy: 0.8591\n","Epoch 31/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9851 - val_loss: 0.3486 - val_accuracy: 0.9183\n","Epoch 32/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 0.3280 - val_accuracy: 0.9274\n","Epoch 33/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9993 - val_loss: 0.3430 - val_accuracy: 0.9302\n","Epoch 34/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9958 - val_loss: 0.4366 - val_accuracy: 0.9048\n","Epoch 35/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9921 - val_loss: 0.4278 - val_accuracy: 0.8929\n","Epoch 36/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9926 - val_loss: 0.4689 - val_accuracy: 0.8937\n","Epoch 37/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9742 - val_loss: 0.3331 - val_accuracy: 0.9302\n","Epoch 38/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.3609 - val_accuracy: 0.9206\n","Epoch 39/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1210 - accuracy: 0.9657 - val_loss: 0.3923 - val_accuracy: 0.9079\n","Epoch 40/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9952 - val_loss: 0.3072 - val_accuracy: 0.9373\n","Epoch 41/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9961 - val_loss: 0.4953 - val_accuracy: 0.8937\n","Epoch 42/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.3451 - val_accuracy: 0.9274\n","Epoch 43/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.3526 - val_accuracy: 0.9266\n","Epoch 44/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9899 - val_loss: 0.4365 - val_accuracy: 0.9063\n","Epoch 45/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9834 - val_loss: 0.4916 - val_accuracy: 0.9012\n","Epoch 46/100\n","143/143 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9650 - val_loss: 0.5208 - val_accuracy: 0.8905\n","Epoch 47/100\n","124/143 [=========================>....] - ETA: 0s - loss: 0.0166 - accuracy: 0.9975\n","Reached at expected accuracy level on the validation set, so cancelling training!\n","143/143 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9978 - val_loss: 0.3216 - val_accuracy: 0.9393\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W_6Hh6IrL68s","colab_type":"text"},"source":["#### 1.3 Model with an additional set of Conv2D+MaxPooling2D layers with the base model, Validation accurcy = 96%"]},{"cell_type":"code","metadata":{"id":"L7rBwq8LMTLJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":756},"executionInfo":{"status":"ok","timestamp":1598001565944,"user_tz":-120,"elapsed":8145,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"06a4f7d6-ddf2-4382-a475-6d85209a7da0"},"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, input_shape=(28, 28, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n","])\n","\n","\n","callbacks = myCallback(0.95)  \n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","history = model.fit(Trainingimages28, y_train, validation_data=(Testimages28, y_test), \n","          epochs=100, callbacks=[callbacks])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 26, 26, 64)        1792      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","flatten_16 (Flatten)         (None, 10816)             0         \n","_________________________________________________________________\n","dense_32 (Dense)             (None, 256)               2769152   \n","_________________________________________________________________\n","dense_33 (Dense)             (None, 62)                15934     \n","=================================================================\n","Total params: 2,786,878\n","Trainable params: 2,786,878\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","143/143 [==============================] - 1s 5ms/step - loss: 1.5186 - accuracy: 0.6610 - val_loss: 0.7493 - val_accuracy: 0.8298\n","Epoch 2/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.3435 - accuracy: 0.9196 - val_loss: 0.3484 - val_accuracy: 0.9226\n","Epoch 3/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.1353 - accuracy: 0.9729 - val_loss: 0.3086 - val_accuracy: 0.9087\n","Epoch 4/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9858 - val_loss: 0.2561 - val_accuracy: 0.9333\n","Epoch 5/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.9906 - val_loss: 0.2405 - val_accuracy: 0.9302\n","Epoch 6/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9976 - val_loss: 0.2467 - val_accuracy: 0.9357\n","Epoch 7/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0216 - accuracy: 0.9952 - val_loss: 0.2176 - val_accuracy: 0.9444\n","Epoch 8/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.2450 - val_accuracy: 0.9373\n","Epoch 9/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.2239 - val_accuracy: 0.9484\n","Epoch 10/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9980 - val_loss: 0.2244 - val_accuracy: 0.9429\n","Epoch 11/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9974 - val_loss: 0.2474 - val_accuracy: 0.9365\n","Epoch 12/100\n","142/143 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9971\n","Reached at the expected accuracy level on the validation set, so cancelling training!\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.1997 - val_accuracy: 0.9603\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fbyNuxqFrSTB","colab_type":"text"},"source":["#### 1.4 Adding 3 Dropout layers with the previos model, Validation accuracy = 96.55% "]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Uj12up-6zR_t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598002042498,"user_tz":-120,"elapsed":58901,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"02d95a70-e835-491d-8124-15c5bc8e4c40"},"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, input_shape=(28, 28, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Dropout(.2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(.3),\n","    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n","    tf.keras.layers.Dropout(.4),\n","    tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n","\n","])\n","\n","callbacks = myCallback(0.965)  \n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","history = model.fit(Trainingimages28, y_train, validation_data=(Testimages28, y_test), \n","          epochs=100, callbacks=[callbacks])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_7 (Conv2D)            (None, 26, 26, 64)        1792      \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","flatten_19 (Flatten)         (None, 10816)             0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 10816)             0         \n","_________________________________________________________________\n","dense_38 (Dense)             (None, 256)               2769152   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_39 (Dense)             (None, 62)                15934     \n","=================================================================\n","Total params: 2,786,878\n","Trainable params: 2,786,878\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","143/143 [==============================] - 1s 6ms/step - loss: 2.0936 - accuracy: 0.5222 - val_loss: 0.9820 - val_accuracy: 0.7948\n","Epoch 2/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.7609 - accuracy: 0.8133 - val_loss: 0.4780 - val_accuracy: 0.8996\n","Epoch 3/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.3894 - accuracy: 0.9001 - val_loss: 0.3519 - val_accuracy: 0.9060\n","Epoch 4/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.2513 - accuracy: 0.9331 - val_loss: 0.2604 - val_accuracy: 0.9373\n","Epoch 5/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.1677 - accuracy: 0.9561 - val_loss: 0.2346 - val_accuracy: 0.9448\n","Epoch 6/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.1305 - accuracy: 0.9617 - val_loss: 0.2230 - val_accuracy: 0.9381\n","Epoch 7/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9709 - val_loss: 0.2090 - val_accuracy: 0.9448\n","Epoch 8/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0752 - accuracy: 0.9823 - val_loss: 0.2087 - val_accuracy: 0.9460\n","Epoch 9/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0684 - accuracy: 0.9812 - val_loss: 0.1877 - val_accuracy: 0.9528\n","Epoch 10/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0650 - accuracy: 0.9834 - val_loss: 0.1775 - val_accuracy: 0.9560\n","Epoch 11/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0560 - accuracy: 0.9856 - val_loss: 0.1768 - val_accuracy: 0.9571\n","Epoch 12/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0399 - accuracy: 0.9902 - val_loss: 0.1990 - val_accuracy: 0.9512\n","Epoch 13/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9904 - val_loss: 0.2182 - val_accuracy: 0.9516\n","Epoch 14/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0395 - accuracy: 0.9897 - val_loss: 0.2108 - val_accuracy: 0.9532\n","Epoch 15/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0439 - accuracy: 0.9878 - val_loss: 0.2172 - val_accuracy: 0.9464\n","Epoch 16/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9873 - val_loss: 0.1941 - val_accuracy: 0.9567\n","Epoch 17/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0485 - accuracy: 0.9873 - val_loss: 0.1932 - val_accuracy: 0.9591\n","Epoch 18/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9886 - val_loss: 0.2119 - val_accuracy: 0.9583\n","Epoch 19/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9908 - val_loss: 0.1998 - val_accuracy: 0.9603\n","Epoch 20/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.2063 - val_accuracy: 0.9623\n","Epoch 21/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9864 - val_loss: 0.2361 - val_accuracy: 0.9524\n","Epoch 22/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 0.2309 - val_accuracy: 0.9548\n","Epoch 23/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.2206 - val_accuracy: 0.9552\n","Epoch 24/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9919 - val_loss: 0.3437 - val_accuracy: 0.9365\n","Epoch 25/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.2180 - val_accuracy: 0.9563\n","Epoch 26/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0259 - accuracy: 0.9910 - val_loss: 0.2271 - val_accuracy: 0.9528\n","Epoch 27/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9899 - val_loss: 0.2624 - val_accuracy: 0.9520\n","Epoch 28/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.2636 - val_accuracy: 0.9508\n","Epoch 29/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.2641 - val_accuracy: 0.9468\n","Epoch 30/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9943 - val_loss: 0.2195 - val_accuracy: 0.9563\n","Epoch 31/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.2100 - val_accuracy: 0.9563\n","Epoch 32/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.2421 - val_accuracy: 0.9548\n","Epoch 33/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9928 - val_loss: 0.2338 - val_accuracy: 0.9548\n","Epoch 34/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.2409 - val_accuracy: 0.9544\n","Epoch 35/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9904 - val_loss: 0.2664 - val_accuracy: 0.9544\n","Epoch 36/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0221 - accuracy: 0.9934 - val_loss: 0.2508 - val_accuracy: 0.9563\n","Epoch 37/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9910 - val_loss: 0.3103 - val_accuracy: 0.9528\n","Epoch 38/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9913 - val_loss: 0.2303 - val_accuracy: 0.9615\n","Epoch 39/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.2681 - val_accuracy: 0.9571\n","Epoch 40/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.3134 - val_accuracy: 0.9540\n","Epoch 41/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.2604 - val_accuracy: 0.9575\n","Epoch 42/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.2779 - val_accuracy: 0.9583\n","Epoch 43/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.2416 - val_accuracy: 0.9575\n","Epoch 44/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 0.2703 - val_accuracy: 0.9464\n","Epoch 45/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.2466 - val_accuracy: 0.9591\n","Epoch 46/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.2877 - val_accuracy: 0.9524\n","Epoch 47/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.3240 - val_accuracy: 0.9500\n","Epoch 48/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.2827 - val_accuracy: 0.9599\n","Epoch 49/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.2944 - val_accuracy: 0.9512\n","Epoch 50/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.2965 - val_accuracy: 0.9536\n","Epoch 51/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.3184 - val_accuracy: 0.9512\n","Epoch 52/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.3279 - val_accuracy: 0.9567\n","Epoch 53/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.3216 - val_accuracy: 0.9544\n","Epoch 54/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9934 - val_loss: 0.2993 - val_accuracy: 0.9595\n","Epoch 55/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 0.4452 - val_accuracy: 0.9365\n","Epoch 56/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.3189 - val_accuracy: 0.9504\n","Epoch 57/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.2879 - val_accuracy: 0.9540\n","Epoch 58/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.3138 - val_accuracy: 0.9544\n","Epoch 59/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9913 - val_loss: 0.3501 - val_accuracy: 0.9524\n","Epoch 60/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.3052 - val_accuracy: 0.9563\n","Epoch 61/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.3518 - val_accuracy: 0.9492\n","Epoch 62/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.3264 - val_accuracy: 0.9544\n","Epoch 63/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.3297 - val_accuracy: 0.9528\n","Epoch 64/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.3090 - val_accuracy: 0.9567\n","Epoch 65/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.9943 - val_loss: 0.3255 - val_accuracy: 0.9532\n","Epoch 66/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.3204 - val_accuracy: 0.9548\n","Epoch 67/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.2907 - val_accuracy: 0.9560\n","Epoch 68/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.3567 - val_accuracy: 0.9496\n","Epoch 69/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.3227 - val_accuracy: 0.9563\n","Epoch 70/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.3435 - val_accuracy: 0.9496\n","Epoch 71/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.3280 - val_accuracy: 0.9571\n","Epoch 72/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.3128 - val_accuracy: 0.9548\n","Epoch 73/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.3637 - val_accuracy: 0.9508\n","Epoch 74/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.4259 - val_accuracy: 0.9504\n","Epoch 75/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9926 - val_loss: 0.3757 - val_accuracy: 0.9544\n","Epoch 76/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.4484 - val_accuracy: 0.9377\n","Epoch 77/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.3686 - val_accuracy: 0.9472\n","Epoch 78/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.3522 - val_accuracy: 0.9472\n","Epoch 79/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.3524 - val_accuracy: 0.9496\n","Epoch 80/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.3736 - val_accuracy: 0.9516\n","Epoch 81/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.4290 - val_accuracy: 0.9468\n","Epoch 82/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.4050 - val_accuracy: 0.9524\n","Epoch 83/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.3823 - val_accuracy: 0.9548\n","Epoch 84/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.4633 - val_accuracy: 0.9433\n","Epoch 85/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.3574 - val_accuracy: 0.9548\n","Epoch 86/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.4059 - val_accuracy: 0.9472\n","Epoch 87/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 0.4082 - val_accuracy: 0.9440\n","Epoch 88/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.3763 - val_accuracy: 0.9464\n","Epoch 89/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.3685 - val_accuracy: 0.9548\n","Epoch 90/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9943 - val_loss: 0.3234 - val_accuracy: 0.9579\n","Epoch 91/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.3658 - val_accuracy: 0.9583\n","Epoch 92/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.3567 - val_accuracy: 0.9563\n","Epoch 93/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.4022 - val_accuracy: 0.9524\n","Epoch 94/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9969 - val_loss: 0.3420 - val_accuracy: 0.9591\n","Epoch 95/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0255 - accuracy: 0.9943 - val_loss: 0.3724 - val_accuracy: 0.9480\n","Epoch 96/100\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.3809 - val_accuracy: 0.9571\n","Epoch 97/100\n","133/143 [==========================>...] - ETA: 0s - loss: 0.0086 - accuracy: 0.9967\n","Reached at the expected accuracy level on the validation set, so cancelling training!\n","143/143 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.3172 - val_accuracy: 0.9655\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KlfvJk__yTE7","colab_type":"text"},"source":["### 1.5 Model with 2 sets ConV+Pooling+Dropout layers with the base model, Validation accuracy = 98.2% \n","\n"," "]},{"cell_type":"code","metadata":{"scrolled":false,"id":"YJu5pcrezSAa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598003366363,"user_tz":-120,"elapsed":35608,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"d34b066e-bddd-43cf-ecbf-d274b185274e"},"source":["       \n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(128, (3,3), activation=tf.nn.relu, input_shape=(28, 28, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Dropout(.2),\n","    tf.keras.layers.Conv2D(256, (3,3), activation=tf.nn.relu),\n","    tf.keras.layers.MaxPooling2D(2,2), \n","    tf.keras.layers.Dropout(.3),   \n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(.2),\n","    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","    tf.keras.layers.Dropout(.5),\n","    tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n","\n","])\n","\n","callbacks = myCallback(0.982)\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","history = model.fit(Trainingimages28, y_train, validation_data=(Testimages28, y_test), \n","          epochs=100, callbacks=[callbacks])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_21\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_10 (Conv2D)           (None, 26, 26, 128)       3584      \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 13, 13, 128)       0         \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 13, 13, 128)       0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 11, 11, 256)       295168    \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","flatten_21 (Flatten)         (None, 6400)              0         \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 6400)              0         \n","_________________________________________________________________\n","dense_42 (Dense)             (None, 512)               3277312   \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_43 (Dense)             (None, 62)                31806     \n","=================================================================\n","Total params: 3,607,870\n","Trainable params: 3,607,870\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","143/143 [==============================] - 1s 7ms/step - loss: 2.3473 - accuracy: 0.4302 - val_loss: 1.1004 - val_accuracy: 0.7714\n","Epoch 2/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.8704 - accuracy: 0.7760 - val_loss: 0.4285 - val_accuracy: 0.9274\n","Epoch 3/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.4413 - accuracy: 0.8789 - val_loss: 0.2495 - val_accuracy: 0.9369\n","Epoch 4/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.2737 - accuracy: 0.9211 - val_loss: 0.1626 - val_accuracy: 0.9528\n","Epoch 5/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.1975 - accuracy: 0.9421 - val_loss: 0.1694 - val_accuracy: 0.9579\n","Epoch 6/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.1518 - accuracy: 0.9567 - val_loss: 0.1413 - val_accuracy: 0.9651\n","Epoch 7/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.1152 - accuracy: 0.9677 - val_loss: 0.1561 - val_accuracy: 0.9651\n","Epoch 8/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0921 - accuracy: 0.9696 - val_loss: 0.1452 - val_accuracy: 0.9635\n","Epoch 9/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0886 - accuracy: 0.9753 - val_loss: 0.1380 - val_accuracy: 0.9687\n","Epoch 10/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0794 - accuracy: 0.9781 - val_loss: 0.1478 - val_accuracy: 0.9722\n","Epoch 11/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0662 - accuracy: 0.9801 - val_loss: 0.1121 - val_accuracy: 0.9766\n","Epoch 12/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0634 - accuracy: 0.9779 - val_loss: 0.1285 - val_accuracy: 0.9738\n","Epoch 13/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0581 - accuracy: 0.9840 - val_loss: 0.1215 - val_accuracy: 0.9734\n","Epoch 14/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0587 - accuracy: 0.9803 - val_loss: 0.1184 - val_accuracy: 0.9746\n","Epoch 15/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0424 - accuracy: 0.9882 - val_loss: 0.1559 - val_accuracy: 0.9690\n","Epoch 16/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.1468 - val_accuracy: 0.9710\n","Epoch 17/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0436 - accuracy: 0.9862 - val_loss: 0.1389 - val_accuracy: 0.9742\n","Epoch 18/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0439 - accuracy: 0.9880 - val_loss: 0.1586 - val_accuracy: 0.9690\n","Epoch 19/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0777 - accuracy: 0.9803 - val_loss: 0.1439 - val_accuracy: 0.9702\n","Epoch 20/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0393 - accuracy: 0.9851 - val_loss: 0.1307 - val_accuracy: 0.9754\n","Epoch 21/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 0.1411 - val_accuracy: 0.9782\n","Epoch 22/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0458 - accuracy: 0.9880 - val_loss: 0.1480 - val_accuracy: 0.9694\n","Epoch 23/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0352 - accuracy: 0.9899 - val_loss: 0.1379 - val_accuracy: 0.9742\n","Epoch 24/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0383 - accuracy: 0.9893 - val_loss: 0.1828 - val_accuracy: 0.9675\n","Epoch 25/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0377 - accuracy: 0.9875 - val_loss: 0.1345 - val_accuracy: 0.9770\n","Epoch 26/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.1946 - val_accuracy: 0.9639\n","Epoch 27/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0433 - accuracy: 0.9878 - val_loss: 0.1322 - val_accuracy: 0.9766\n","Epoch 28/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0353 - accuracy: 0.9889 - val_loss: 0.2066 - val_accuracy: 0.9643\n","Epoch 29/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0425 - accuracy: 0.9895 - val_loss: 0.1421 - val_accuracy: 0.9754\n","Epoch 30/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0310 - accuracy: 0.9891 - val_loss: 0.1582 - val_accuracy: 0.9726\n","Epoch 31/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0379 - accuracy: 0.9880 - val_loss: 0.1472 - val_accuracy: 0.9766\n","Epoch 32/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 0.1611 - val_accuracy: 0.9746\n","Epoch 33/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.1452 - val_accuracy: 0.9794\n","Epoch 34/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0314 - accuracy: 0.9921 - val_loss: 0.1724 - val_accuracy: 0.9778\n","Epoch 35/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 0.1472 - val_accuracy: 0.9734\n","Epoch 36/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0338 - accuracy: 0.9904 - val_loss: 0.1540 - val_accuracy: 0.9714\n","Epoch 37/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0288 - accuracy: 0.9926 - val_loss: 0.1347 - val_accuracy: 0.9782\n","Epoch 38/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0509 - accuracy: 0.9862 - val_loss: 0.1871 - val_accuracy: 0.9754\n","Epoch 39/100\n","142/143 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9930\n","Reached at the expected accuracy level on the validation set, so cancelling training!\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.1682 - val_accuracy: 0.9821\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2mX2ENrWcdZy","colab_type":"text"},"source":["### 1.6 Results summary with lower resolution images (28-28-3) \n","So far we have achieved 98.2% accuracy on the validation set. \n","\n","#### Still we can try few more options with low resolution images\n","- Try padding, striding or both\n","- Apply image augmentation techniques\n","- Apply dilated convolution \n","- Try with gray scale images"]},{"cell_type":"markdown","metadata":{"id":"MbrG8mPAeAqK","colab_type":"text"},"source":["###In fact padding and/or striding do not incease the accuracy (not shown here). let's try image augmentation and dilated convolution. "]},{"cell_type":"markdown","metadata":{"id":"_hq1gOf1x4AC","colab_type":"text"},"source":["#### 1.6.1 Data Augmentation does not help with or without rescaling, because of lower accuracy\n","\n","maximum accuracy achieved : 96.3% (Please see below at epoch = 94)"]},{"cell_type":"code","metadata":{"id":"cPKMDgWKFoUW","colab_type":"code","colab":{}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator   \n","\n","train_datagen = ImageDataGenerator(\n","      rotation_range=20,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=False,\n","      fill_mode='nearest')\n","\n","train_datagen.fit(Trainingimages28)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c7FQT_qvAzD2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598004955591,"user_tz":-120,"elapsed":246387,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"af3be130-002b-47f3-ed1b-72550b4c9cdb"},"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(128, (3,3), activation=tf.nn.relu, input_shape=(28, 28, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Dropout(.2),\n","    tf.keras.layers.Conv2D(256, (3,3), activation=tf.nn.relu),\n","    tf.keras.layers.MaxPooling2D(2,2), \n","    tf.keras.layers.Dropout(.3),   \n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(.2),\n","    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","    tf.keras.layers.Dropout(.5),\n","    tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n","])\n","\n","callbacks = myCallback(0.985)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","history = model.fit(train_datagen.flow(Trainingimages28, y_train), validation_data=(Testimages28, y_test),  epochs=100, callbacks=[callbacks])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","143/143 [==============================] - 2s 17ms/step - loss: 3.0651 - accuracy: 0.2330 - val_loss: 2.3721 - val_accuracy: 0.4119\n","Epoch 2/100\n","143/143 [==============================] - 2s 17ms/step - loss: 2.3370 - accuracy: 0.3666 - val_loss: 1.8828 - val_accuracy: 0.5119\n","Epoch 3/100\n","143/143 [==============================] - 2s 17ms/step - loss: 1.9237 - accuracy: 0.4649 - val_loss: 1.2931 - val_accuracy: 0.6071\n","Epoch 4/100\n","143/143 [==============================] - 2s 17ms/step - loss: 1.6190 - accuracy: 0.5392 - val_loss: 1.0225 - val_accuracy: 0.6821\n","Epoch 5/100\n","143/143 [==============================] - 2s 17ms/step - loss: 1.3898 - accuracy: 0.6044 - val_loss: 1.0155 - val_accuracy: 0.6770\n","Epoch 6/100\n","143/143 [==============================] - 2s 17ms/step - loss: 1.2465 - accuracy: 0.6385 - val_loss: 0.7686 - val_accuracy: 0.8214\n","Epoch 7/100\n","143/143 [==============================] - 2s 17ms/step - loss: 1.1097 - accuracy: 0.6767 - val_loss: 0.7273 - val_accuracy: 0.7683\n","Epoch 8/100\n","143/143 [==============================] - 2s 17ms/step - loss: 1.0257 - accuracy: 0.6925 - val_loss: 0.6898 - val_accuracy: 0.7952\n","Epoch 9/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.9257 - accuracy: 0.7165 - val_loss: 0.6351 - val_accuracy: 0.7627\n","Epoch 10/100\n","143/143 [==============================] - 3s 18ms/step - loss: 0.8746 - accuracy: 0.7377 - val_loss: 0.5117 - val_accuracy: 0.8683\n","Epoch 11/100\n","143/143 [==============================] - 3s 18ms/step - loss: 0.8182 - accuracy: 0.7548 - val_loss: 0.4587 - val_accuracy: 0.8679\n","Epoch 12/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.7830 - accuracy: 0.7624 - val_loss: 0.4410 - val_accuracy: 0.8913\n","Epoch 13/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.7546 - accuracy: 0.7635 - val_loss: 0.4014 - val_accuracy: 0.8984\n","Epoch 14/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.7036 - accuracy: 0.7799 - val_loss: 0.3474 - val_accuracy: 0.9095\n","Epoch 15/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.6767 - accuracy: 0.7889 - val_loss: 0.3494 - val_accuracy: 0.9040\n","Epoch 16/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.6597 - accuracy: 0.7932 - val_loss: 0.3648 - val_accuracy: 0.9036\n","Epoch 17/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.5826 - accuracy: 0.8256 - val_loss: 0.3240 - val_accuracy: 0.9111\n","Epoch 18/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.6120 - accuracy: 0.8083 - val_loss: 0.3863 - val_accuracy: 0.8909\n","Epoch 19/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.5846 - accuracy: 0.8175 - val_loss: 0.3151 - val_accuracy: 0.9194\n","Epoch 20/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.5383 - accuracy: 0.8328 - val_loss: 0.3182 - val_accuracy: 0.9183\n","Epoch 21/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.5366 - accuracy: 0.8319 - val_loss: 0.3045 - val_accuracy: 0.9071\n","Epoch 22/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.5236 - accuracy: 0.8341 - val_loss: 0.3335 - val_accuracy: 0.9052\n","Epoch 23/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.4994 - accuracy: 0.8391 - val_loss: 0.3222 - val_accuracy: 0.9083\n","Epoch 24/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.5024 - accuracy: 0.8372 - val_loss: 0.2467 - val_accuracy: 0.9373\n","Epoch 25/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.4810 - accuracy: 0.8481 - val_loss: 0.2586 - val_accuracy: 0.9250\n","Epoch 26/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.4801 - accuracy: 0.8450 - val_loss: 0.2676 - val_accuracy: 0.9190\n","Epoch 27/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.4333 - accuracy: 0.8640 - val_loss: 0.2780 - val_accuracy: 0.9190\n","Epoch 28/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.4601 - accuracy: 0.8566 - val_loss: 0.2627 - val_accuracy: 0.9321\n","Epoch 29/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.4312 - accuracy: 0.8662 - val_loss: 0.2520 - val_accuracy: 0.9274\n","Epoch 30/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3944 - accuracy: 0.8758 - val_loss: 0.2269 - val_accuracy: 0.9302\n","Epoch 31/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.4151 - accuracy: 0.8717 - val_loss: 0.2097 - val_accuracy: 0.9448\n","Epoch 32/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3972 - accuracy: 0.8710 - val_loss: 0.2167 - val_accuracy: 0.9425\n","Epoch 33/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3679 - accuracy: 0.8857 - val_loss: 0.2145 - val_accuracy: 0.9377\n","Epoch 34/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.4234 - accuracy: 0.8664 - val_loss: 0.2168 - val_accuracy: 0.9393\n","Epoch 35/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3923 - accuracy: 0.8745 - val_loss: 0.2252 - val_accuracy: 0.9377\n","Epoch 36/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.4121 - accuracy: 0.8776 - val_loss: 0.2137 - val_accuracy: 0.9413\n","Epoch 37/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3491 - accuracy: 0.8863 - val_loss: 0.2187 - val_accuracy: 0.9409\n","Epoch 38/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3642 - accuracy: 0.8828 - val_loss: 0.2011 - val_accuracy: 0.9484\n","Epoch 39/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3555 - accuracy: 0.8881 - val_loss: 0.2018 - val_accuracy: 0.9444\n","Epoch 40/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3518 - accuracy: 0.8896 - val_loss: 0.2635 - val_accuracy: 0.9306\n","Epoch 41/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3501 - accuracy: 0.8855 - val_loss: 0.2294 - val_accuracy: 0.9401\n","Epoch 42/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3571 - accuracy: 0.8839 - val_loss: 0.2219 - val_accuracy: 0.9425\n","Epoch 43/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3310 - accuracy: 0.8922 - val_loss: 0.2358 - val_accuracy: 0.9468\n","Epoch 44/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3414 - accuracy: 0.8874 - val_loss: 0.2357 - val_accuracy: 0.9429\n","Epoch 45/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3254 - accuracy: 0.8968 - val_loss: 0.2365 - val_accuracy: 0.9365\n","Epoch 46/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3182 - accuracy: 0.8975 - val_loss: 0.2257 - val_accuracy: 0.9456\n","Epoch 47/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3446 - accuracy: 0.8903 - val_loss: 0.2209 - val_accuracy: 0.9409\n","Epoch 48/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3282 - accuracy: 0.8927 - val_loss: 0.1898 - val_accuracy: 0.9563\n","Epoch 49/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3234 - accuracy: 0.8957 - val_loss: 0.2195 - val_accuracy: 0.9460\n","Epoch 50/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3036 - accuracy: 0.9047 - val_loss: 0.2175 - val_accuracy: 0.9437\n","Epoch 51/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3066 - accuracy: 0.9023 - val_loss: 0.2173 - val_accuracy: 0.9393\n","Epoch 52/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2875 - accuracy: 0.9091 - val_loss: 0.1956 - val_accuracy: 0.9472\n","Epoch 53/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3086 - accuracy: 0.8975 - val_loss: 0.1885 - val_accuracy: 0.9536\n","Epoch 54/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2740 - accuracy: 0.9078 - val_loss: 0.2075 - val_accuracy: 0.9456\n","Epoch 55/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2967 - accuracy: 0.9003 - val_loss: 0.2171 - val_accuracy: 0.9405\n","Epoch 56/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.3078 - accuracy: 0.9047 - val_loss: 0.2384 - val_accuracy: 0.9377\n","Epoch 57/100\n","143/143 [==============================] - 2s 16ms/step - loss: 0.2774 - accuracy: 0.9091 - val_loss: 0.2347 - val_accuracy: 0.9365\n","Epoch 58/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2853 - accuracy: 0.9108 - val_loss: 0.2225 - val_accuracy: 0.9405\n","Epoch 59/100\n","143/143 [==============================] - 2s 16ms/step - loss: 0.2859 - accuracy: 0.9067 - val_loss: 0.2149 - val_accuracy: 0.9480\n","Epoch 60/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2885 - accuracy: 0.9080 - val_loss: 0.2185 - val_accuracy: 0.9444\n","Epoch 61/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2930 - accuracy: 0.9051 - val_loss: 0.2170 - val_accuracy: 0.9369\n","Epoch 62/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2735 - accuracy: 0.9128 - val_loss: 0.2126 - val_accuracy: 0.9484\n","Epoch 63/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2525 - accuracy: 0.9228 - val_loss: 0.2184 - val_accuracy: 0.9460\n","Epoch 64/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2898 - accuracy: 0.9110 - val_loss: 0.2176 - val_accuracy: 0.9401\n","Epoch 65/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2726 - accuracy: 0.9108 - val_loss: 0.2015 - val_accuracy: 0.9480\n","Epoch 66/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2523 - accuracy: 0.9187 - val_loss: 0.1746 - val_accuracy: 0.9532\n","Epoch 67/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2722 - accuracy: 0.9141 - val_loss: 0.2473 - val_accuracy: 0.9321\n","Epoch 68/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2551 - accuracy: 0.9176 - val_loss: 0.2340 - val_accuracy: 0.9393\n","Epoch 69/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2653 - accuracy: 0.9165 - val_loss: 0.1818 - val_accuracy: 0.9567\n","Epoch 70/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2241 - accuracy: 0.9311 - val_loss: 0.2076 - val_accuracy: 0.9484\n","Epoch 71/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2498 - accuracy: 0.9244 - val_loss: 0.1948 - val_accuracy: 0.9536\n","Epoch 72/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2335 - accuracy: 0.9237 - val_loss: 0.1904 - val_accuracy: 0.9496\n","Epoch 73/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2323 - accuracy: 0.9266 - val_loss: 0.1928 - val_accuracy: 0.9556\n","Epoch 74/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2555 - accuracy: 0.9196 - val_loss: 0.1794 - val_accuracy: 0.9599\n","Epoch 75/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2492 - accuracy: 0.9244 - val_loss: 0.1746 - val_accuracy: 0.9623\n","Epoch 76/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2456 - accuracy: 0.9207 - val_loss: 0.1827 - val_accuracy: 0.9563\n","Epoch 77/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2491 - accuracy: 0.9207 - val_loss: 0.2022 - val_accuracy: 0.9544\n","Epoch 78/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2456 - accuracy: 0.9183 - val_loss: 0.1904 - val_accuracy: 0.9548\n","Epoch 79/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2523 - accuracy: 0.9242 - val_loss: 0.2031 - val_accuracy: 0.9480\n","Epoch 80/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2289 - accuracy: 0.9239 - val_loss: 0.1965 - val_accuracy: 0.9579\n","Epoch 81/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2409 - accuracy: 0.9246 - val_loss: 0.1973 - val_accuracy: 0.9599\n","Epoch 82/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2414 - accuracy: 0.9237 - val_loss: 0.1946 - val_accuracy: 0.9591\n","Epoch 83/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2155 - accuracy: 0.9311 - val_loss: 0.2027 - val_accuracy: 0.9556\n","Epoch 84/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2192 - accuracy: 0.9325 - val_loss: 0.2102 - val_accuracy: 0.9556\n","Epoch 85/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2417 - accuracy: 0.9279 - val_loss: 0.1837 - val_accuracy: 0.9655\n","Epoch 86/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2203 - accuracy: 0.9327 - val_loss: 0.2064 - val_accuracy: 0.9607\n","Epoch 87/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2176 - accuracy: 0.9325 - val_loss: 0.2149 - val_accuracy: 0.9548\n","Epoch 88/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2399 - accuracy: 0.9242 - val_loss: 0.1968 - val_accuracy: 0.9603\n","Epoch 89/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2339 - accuracy: 0.9298 - val_loss: 0.1911 - val_accuracy: 0.9599\n","Epoch 90/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2220 - accuracy: 0.9290 - val_loss: 0.1889 - val_accuracy: 0.9512\n","Epoch 91/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2257 - accuracy: 0.9290 - val_loss: 0.1853 - val_accuracy: 0.9595\n","Epoch 92/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2308 - accuracy: 0.9318 - val_loss: 0.1850 - val_accuracy: 0.9611\n","Epoch 93/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2145 - accuracy: 0.9333 - val_loss: 0.1663 - val_accuracy: 0.9659\n","Epoch 94/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2089 - accuracy: 0.9342 - val_loss: 0.1744 - val_accuracy: 0.9631\n","Epoch 95/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2057 - accuracy: 0.9349 - val_loss: 0.1980 - val_accuracy: 0.9611\n","Epoch 96/100\n","143/143 [==============================] - 3s 18ms/step - loss: 0.2188 - accuracy: 0.9318 - val_loss: 0.1746 - val_accuracy: 0.9619\n","Epoch 97/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2049 - accuracy: 0.9349 - val_loss: 0.1910 - val_accuracy: 0.9552\n","Epoch 98/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.1962 - accuracy: 0.9386 - val_loss: 0.1996 - val_accuracy: 0.9532\n","Epoch 99/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2077 - accuracy: 0.9329 - val_loss: 0.1880 - val_accuracy: 0.9607\n","Epoch 100/100\n","143/143 [==============================] - 2s 17ms/step - loss: 0.2120 - accuracy: 0.9349 - val_loss: 0.1862 - val_accuracy: 0.9571\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gslGnPFdiA6m","colab_type":"text"},"source":["#### 1.6.2 Let's see the effect of dilated convolution on the best CNN architecture so far\n","\n","- dilation_rate=2 with first Conv2D layer gives upto 97.9% (at epoch = 45) accuracy only. So dilated convolution does not increase accuracy for 28-28-3 images "]},{"cell_type":"code","metadata":{"id":"7nUo9GgpjCN8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598005660124,"user_tz":-120,"elapsed":96670,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"25572029-d9e8-4eb4-b4f8-966acb622f60"},"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(128, (3,3), dilation_rate=2, activation=tf.nn.relu, input_shape=(28, 28, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Dropout(.2),\n","    tf.keras.layers.Conv2D(256, (3,3), activation=tf.nn.relu),\n","    tf.keras.layers.MaxPooling2D(2,2), \n","    tf.keras.layers.Dropout(.3),   \n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(.2),\n","    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","    tf.keras.layers.Dropout(.5),\n","    tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n","\n","])\n","\n","callbacks = myCallback(0.984)\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","history = model.fit(Trainingimages28, y_train, validation_data=(Testimages28, y_test), \n","          epochs=100, callbacks=[callbacks])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_24\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_16 (Conv2D)           (None, 24, 24, 128)       3584      \n","_________________________________________________________________\n","max_pooling2d_16 (MaxPooling (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","dropout_25 (Dropout)         (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 10, 10, 256)       295168    \n","_________________________________________________________________\n","max_pooling2d_17 (MaxPooling (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","dropout_26 (Dropout)         (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","flatten_24 (Flatten)         (None, 6400)              0         \n","_________________________________________________________________\n","dropout_27 (Dropout)         (None, 6400)              0         \n","_________________________________________________________________\n","dense_48 (Dense)             (None, 512)               3277312   \n","_________________________________________________________________\n","dropout_28 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_49 (Dense)             (None, 62)                31806     \n","=================================================================\n","Total params: 3,607,870\n","Trainable params: 3,607,870\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","143/143 [==============================] - 1s 8ms/step - loss: 2.2343 - accuracy: 0.4627 - val_loss: 0.9692 - val_accuracy: 0.7579\n","Epoch 2/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.7569 - accuracy: 0.8017 - val_loss: 0.4263 - val_accuracy: 0.8917\n","Epoch 3/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8835 - val_loss: 0.2810 - val_accuracy: 0.9306\n","Epoch 4/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.2539 - accuracy: 0.9301 - val_loss: 0.2065 - val_accuracy: 0.9488\n","Epoch 5/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.1959 - accuracy: 0.9451 - val_loss: 0.1958 - val_accuracy: 0.9508\n","Epoch 6/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.1566 - accuracy: 0.9589 - val_loss: 0.2025 - val_accuracy: 0.9500\n","Epoch 7/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.1272 - accuracy: 0.9609 - val_loss: 0.1902 - val_accuracy: 0.9563\n","Epoch 8/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0985 - accuracy: 0.9753 - val_loss: 0.1945 - val_accuracy: 0.9536\n","Epoch 9/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0862 - accuracy: 0.9753 - val_loss: 0.1973 - val_accuracy: 0.9540\n","Epoch 10/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0697 - accuracy: 0.9788 - val_loss: 0.1536 - val_accuracy: 0.9687\n","Epoch 11/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0705 - accuracy: 0.9773 - val_loss: 0.1900 - val_accuracy: 0.9595\n","Epoch 12/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0743 - accuracy: 0.9773 - val_loss: 0.1655 - val_accuracy: 0.9647\n","Epoch 13/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0656 - accuracy: 0.9816 - val_loss: 0.1685 - val_accuracy: 0.9683\n","Epoch 14/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9858 - val_loss: 0.1721 - val_accuracy: 0.9639\n","Epoch 15/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0596 - accuracy: 0.9814 - val_loss: 0.2040 - val_accuracy: 0.9556\n","Epoch 16/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 0.1655 - val_accuracy: 0.9710\n","Epoch 17/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0500 - accuracy: 0.9858 - val_loss: 0.1391 - val_accuracy: 0.9746\n","Epoch 18/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9908 - val_loss: 0.1634 - val_accuracy: 0.9734\n","Epoch 19/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0385 - accuracy: 0.9889 - val_loss: 0.1477 - val_accuracy: 0.9742\n","Epoch 20/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0651 - accuracy: 0.9803 - val_loss: 0.1796 - val_accuracy: 0.9607\n","Epoch 21/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0459 - accuracy: 0.9869 - val_loss: 0.1652 - val_accuracy: 0.9690\n","Epoch 22/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.1873 - val_accuracy: 0.9687\n","Epoch 23/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0381 - accuracy: 0.9897 - val_loss: 0.1635 - val_accuracy: 0.9754\n","Epoch 24/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9908 - val_loss: 0.2105 - val_accuracy: 0.9615\n","Epoch 25/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0540 - accuracy: 0.9851 - val_loss: 0.1924 - val_accuracy: 0.9627\n","Epoch 26/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0222 - accuracy: 0.9934 - val_loss: 0.2025 - val_accuracy: 0.9698\n","Epoch 27/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 0.2683 - val_accuracy: 0.9655\n","Epoch 28/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.1765 - val_accuracy: 0.9722\n","Epoch 29/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 0.1907 - val_accuracy: 0.9694\n","Epoch 30/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9921 - val_loss: 0.1884 - val_accuracy: 0.9663\n","Epoch 31/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0378 - accuracy: 0.9893 - val_loss: 0.1946 - val_accuracy: 0.9675\n","Epoch 32/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9904 - val_loss: 0.1847 - val_accuracy: 0.9655\n","Epoch 33/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0397 - accuracy: 0.9873 - val_loss: 0.1965 - val_accuracy: 0.9690\n","Epoch 34/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9910 - val_loss: 0.2082 - val_accuracy: 0.9643\n","Epoch 35/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.2015 - val_accuracy: 0.9730\n","Epoch 36/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0232 - accuracy: 0.9919 - val_loss: 0.2276 - val_accuracy: 0.9671\n","Epoch 37/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 0.2087 - val_accuracy: 0.9710\n","Epoch 38/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 0.2377 - val_accuracy: 0.9679\n","Epoch 39/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.2490 - val_accuracy: 0.9667\n","Epoch 40/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0235 - accuracy: 0.9934 - val_loss: 0.2346 - val_accuracy: 0.9643\n","Epoch 41/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 0.2161 - val_accuracy: 0.9631\n","Epoch 42/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.2453 - val_accuracy: 0.9694\n","Epoch 43/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0432 - accuracy: 0.9886 - val_loss: 0.2340 - val_accuracy: 0.9663\n","Epoch 44/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0313 - accuracy: 0.9891 - val_loss: 0.2322 - val_accuracy: 0.9635\n","Epoch 45/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0268 - accuracy: 0.9932 - val_loss: 0.1996 - val_accuracy: 0.9790\n","Epoch 46/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.1946 - val_accuracy: 0.9774\n","Epoch 47/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.2072 - val_accuracy: 0.9758\n","Epoch 48/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.2434 - val_accuracy: 0.9698\n","Epoch 49/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.2423 - val_accuracy: 0.9766\n","Epoch 50/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0366 - accuracy: 0.9893 - val_loss: 0.2540 - val_accuracy: 0.9663\n","Epoch 51/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.2353 - val_accuracy: 0.9690\n","Epoch 52/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.2070 - val_accuracy: 0.9722\n","Epoch 53/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.2231 - val_accuracy: 0.9730\n","Epoch 54/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.2258 - val_accuracy: 0.9742\n","Epoch 55/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0275 - accuracy: 0.9919 - val_loss: 0.1998 - val_accuracy: 0.9710\n","Epoch 56/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.2227 - val_accuracy: 0.9683\n","Epoch 57/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 0.2492 - val_accuracy: 0.9687\n","Epoch 58/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.2473 - val_accuracy: 0.9690\n","Epoch 59/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.2346 - val_accuracy: 0.9754\n","Epoch 60/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.2725 - val_accuracy: 0.9683\n","Epoch 61/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.2765 - val_accuracy: 0.9687\n","Epoch 62/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.2600 - val_accuracy: 0.9742\n","Epoch 63/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9923 - val_loss: 0.5188 - val_accuracy: 0.9405\n","Epoch 64/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.2447 - val_accuracy: 0.9710\n","Epoch 65/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.3208 - val_accuracy: 0.9671\n","Epoch 66/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 0.3238 - val_accuracy: 0.9690\n","Epoch 67/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.2680 - val_accuracy: 0.9710\n","Epoch 68/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.2865 - val_accuracy: 0.9726\n","Epoch 69/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.2966 - val_accuracy: 0.9714\n","Epoch 70/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.2926 - val_accuracy: 0.9675\n","Epoch 71/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.2962 - val_accuracy: 0.9639\n","Epoch 72/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0286 - accuracy: 0.9941 - val_loss: 0.2471 - val_accuracy: 0.9738\n","Epoch 73/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 0.2959 - val_accuracy: 0.9722\n","Epoch 74/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.3454 - val_accuracy: 0.9655\n","Epoch 75/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0260 - accuracy: 0.9928 - val_loss: 0.2635 - val_accuracy: 0.9639\n","Epoch 76/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0228 - accuracy: 0.9945 - val_loss: 0.2853 - val_accuracy: 0.9722\n","Epoch 77/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.3021 - val_accuracy: 0.9718\n","Epoch 78/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.2366 - val_accuracy: 0.9738\n","Epoch 79/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.2883 - val_accuracy: 0.9746\n","Epoch 80/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.2657 - val_accuracy: 0.9762\n","Epoch 81/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 0.3011 - val_accuracy: 0.9734\n","Epoch 82/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0293 - accuracy: 0.9926 - val_loss: 0.3166 - val_accuracy: 0.9694\n","Epoch 83/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0165 - accuracy: 0.9967 - val_loss: 0.2829 - val_accuracy: 0.9667\n","Epoch 84/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 0.2670 - val_accuracy: 0.9687\n","Epoch 85/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.3514 - val_accuracy: 0.9567\n","Epoch 86/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.2974 - val_accuracy: 0.9603\n","Epoch 87/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 0.3072 - val_accuracy: 0.9659\n","Epoch 88/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9913 - val_loss: 0.2740 - val_accuracy: 0.9663\n","Epoch 89/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.2553 - val_accuracy: 0.9774\n","Epoch 90/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.2487 - val_accuracy: 0.9766\n","Epoch 91/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.2990 - val_accuracy: 0.9778\n","Epoch 92/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.3055 - val_accuracy: 0.9762\n","Epoch 93/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.3404 - val_accuracy: 0.9714\n","Epoch 94/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.2648 - val_accuracy: 0.9730\n","Epoch 95/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0196 - accuracy: 0.9954 - val_loss: 0.3089 - val_accuracy: 0.9738\n","Epoch 96/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0244 - accuracy: 0.9945 - val_loss: 0.2809 - val_accuracy: 0.9766\n","Epoch 97/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0222 - accuracy: 0.9950 - val_loss: 0.2918 - val_accuracy: 0.9734\n","Epoch 98/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.2794 - val_accuracy: 0.9722\n","Epoch 99/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0359 - accuracy: 0.9913 - val_loss: 0.2717 - val_accuracy: 0.9782\n","Epoch 100/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0229 - accuracy: 0.9954 - val_loss: 0.3148 - val_accuracy: 0.9754\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NML82L0XmHhd","colab_type":"text"},"source":["#### 1.6.3 Are gray images effective??\n","\n","If faster training is expected even with little lower accuracy then training with gray images is also fine. Because the same model gives:\n","\n","- 98.2% validation accuracy with RGB images\n","- 97.5% validation accuracy with gray images\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"YtA2pMtBnbID","colab_type":"code","colab":{}},"source":["Trainingimages28gray = np.array(Trainingimages28gray)\n","Trainingimages28gray = Trainingimages28gray.reshape(4575, 28, 28, 1)\n","\n","Testimages28gray = np.array(Testimages28gray)\n","Testimages28gray = Testimages28gray.reshape(2520, 28, 28, 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k718a8d_mQ5s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598007540573,"user_tz":-120,"elapsed":89522,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"1657f91a-767a-4594-ee8a-a690210eb0d2"},"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(128, (3,3), activation=tf.nn.relu, input_shape=(28, 28, 1)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Dropout(.2),\n","    tf.keras.layers.Conv2D(256, (3,3), activation=tf.nn.relu),\n","    tf.keras.layers.MaxPooling2D(2,2), \n","    tf.keras.layers.Dropout(.3),   \n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(.2),\n","    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","    tf.keras.layers.Dropout(.5),\n","    tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n","\n","])\n","\n","callbacks = myCallback(0.982)\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","history = model.fit(Trainingimages28gray, y_train, validation_data=(Testimages28gray, y_test), \n","          epochs=100, callbacks=[callbacks])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_30\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_28 (Conv2D)           (None, 26, 26, 128)       1280      \n","_________________________________________________________________\n","max_pooling2d_28 (MaxPooling (None, 13, 13, 128)       0         \n","_________________________________________________________________\n","dropout_49 (Dropout)         (None, 13, 13, 128)       0         \n","_________________________________________________________________\n","conv2d_29 (Conv2D)           (None, 11, 11, 256)       295168    \n","_________________________________________________________________\n","max_pooling2d_29 (MaxPooling (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","dropout_50 (Dropout)         (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","flatten_30 (Flatten)         (None, 6400)              0         \n","_________________________________________________________________\n","dropout_51 (Dropout)         (None, 6400)              0         \n","_________________________________________________________________\n","dense_60 (Dense)             (None, 512)               3277312   \n","_________________________________________________________________\n","dropout_52 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_61 (Dense)             (None, 62)                31806     \n","=================================================================\n","Total params: 3,605,566\n","Trainable params: 3,605,566\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","143/143 [==============================] - 1s 7ms/step - loss: 2.6044 - accuracy: 0.4000 - val_loss: 1.2783 - val_accuracy: 0.6925\n","Epoch 2/100\n","143/143 [==============================] - 1s 6ms/step - loss: 1.0289 - accuracy: 0.7263 - val_loss: 0.5364 - val_accuracy: 0.8877\n","Epoch 3/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.6081 - accuracy: 0.8251 - val_loss: 0.3604 - val_accuracy: 0.9087\n","Epoch 4/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.4125 - accuracy: 0.8730 - val_loss: 0.2803 - val_accuracy: 0.9230\n","Epoch 5/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.2937 - accuracy: 0.9095 - val_loss: 0.2227 - val_accuracy: 0.9377\n","Epoch 6/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.2324 - accuracy: 0.9246 - val_loss: 0.2084 - val_accuracy: 0.9425\n","Epoch 7/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.1815 - accuracy: 0.9399 - val_loss: 0.1799 - val_accuracy: 0.9571\n","Epoch 8/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.1692 - accuracy: 0.9454 - val_loss: 0.1616 - val_accuracy: 0.9619\n","Epoch 9/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.1393 - accuracy: 0.9545 - val_loss: 0.1647 - val_accuracy: 0.9623\n","Epoch 10/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.1176 - accuracy: 0.9611 - val_loss: 0.1526 - val_accuracy: 0.9635\n","Epoch 11/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.1044 - accuracy: 0.9635 - val_loss: 0.1658 - val_accuracy: 0.9623\n","Epoch 12/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0997 - accuracy: 0.9685 - val_loss: 0.1591 - val_accuracy: 0.9627\n","Epoch 13/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0958 - accuracy: 0.9705 - val_loss: 0.1627 - val_accuracy: 0.9563\n","Epoch 14/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0666 - accuracy: 0.9779 - val_loss: 0.1915 - val_accuracy: 0.9595\n","Epoch 15/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9740 - val_loss: 0.1834 - val_accuracy: 0.9583\n","Epoch 16/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0753 - accuracy: 0.9764 - val_loss: 0.1696 - val_accuracy: 0.9623\n","Epoch 17/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0607 - accuracy: 0.9801 - val_loss: 0.1795 - val_accuracy: 0.9623\n","Epoch 18/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0734 - accuracy: 0.9731 - val_loss: 0.1621 - val_accuracy: 0.9675\n","Epoch 19/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0808 - accuracy: 0.9751 - val_loss: 0.1641 - val_accuracy: 0.9694\n","Epoch 20/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.1784 - val_accuracy: 0.9663\n","Epoch 21/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0732 - accuracy: 0.9775 - val_loss: 0.1712 - val_accuracy: 0.9655\n","Epoch 22/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0400 - accuracy: 0.9880 - val_loss: 0.1861 - val_accuracy: 0.9698\n","Epoch 23/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0500 - accuracy: 0.9827 - val_loss: 0.1857 - val_accuracy: 0.9651\n","Epoch 24/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0494 - accuracy: 0.9830 - val_loss: 0.1658 - val_accuracy: 0.9675\n","Epoch 25/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0466 - accuracy: 0.9871 - val_loss: 0.1896 - val_accuracy: 0.9698\n","Epoch 26/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0375 - accuracy: 0.9867 - val_loss: 0.1784 - val_accuracy: 0.9702\n","Epoch 27/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.1820 - val_accuracy: 0.9714\n","Epoch 28/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0439 - accuracy: 0.9873 - val_loss: 0.2030 - val_accuracy: 0.9647\n","Epoch 29/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0440 - accuracy: 0.9854 - val_loss: 0.1910 - val_accuracy: 0.9698\n","Epoch 30/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0413 - accuracy: 0.9862 - val_loss: 0.1765 - val_accuracy: 0.9698\n","Epoch 31/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.2172 - val_accuracy: 0.9647\n","Epoch 32/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0446 - accuracy: 0.9862 - val_loss: 0.1770 - val_accuracy: 0.9687\n","Epoch 33/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.1847 - val_accuracy: 0.9667\n","Epoch 34/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0407 - accuracy: 0.9860 - val_loss: 0.1988 - val_accuracy: 0.9611\n","Epoch 35/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.1906 - val_accuracy: 0.9702\n","Epoch 36/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.1676 - val_accuracy: 0.9694\n","Epoch 37/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0301 - accuracy: 0.9913 - val_loss: 0.1828 - val_accuracy: 0.9750\n","Epoch 38/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0260 - accuracy: 0.9910 - val_loss: 0.2096 - val_accuracy: 0.9675\n","Epoch 39/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0402 - accuracy: 0.9880 - val_loss: 0.1868 - val_accuracy: 0.9718\n","Epoch 40/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0391 - accuracy: 0.9882 - val_loss: 0.1898 - val_accuracy: 0.9698\n","Epoch 41/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0270 - accuracy: 0.9919 - val_loss: 0.2130 - val_accuracy: 0.9647\n","Epoch 42/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0282 - accuracy: 0.9910 - val_loss: 0.1868 - val_accuracy: 0.9675\n","Epoch 43/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 0.2189 - val_accuracy: 0.9687\n","Epoch 44/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0391 - accuracy: 0.9882 - val_loss: 0.2093 - val_accuracy: 0.9698\n","Epoch 45/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.1889 - val_accuracy: 0.9742\n","Epoch 46/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0314 - accuracy: 0.9919 - val_loss: 0.1884 - val_accuracy: 0.9754\n","Epoch 47/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 0.2062 - val_accuracy: 0.9710\n","Epoch 48/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 0.1891 - val_accuracy: 0.9738\n","Epoch 49/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.2306 - val_accuracy: 0.9687\n","Epoch 50/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.1734 - val_accuracy: 0.9730\n","Epoch 51/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0303 - accuracy: 0.9904 - val_loss: 0.1926 - val_accuracy: 0.9714\n","Epoch 52/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0265 - accuracy: 0.9926 - val_loss: 0.2119 - val_accuracy: 0.9643\n","Epoch 53/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.1904 - val_accuracy: 0.9778\n","Epoch 54/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.2305 - val_accuracy: 0.9694\n","Epoch 55/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.2115 - val_accuracy: 0.9702\n","Epoch 56/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.2211 - val_accuracy: 0.9698\n","Epoch 57/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.2172 - val_accuracy: 0.9706\n","Epoch 58/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0425 - accuracy: 0.9873 - val_loss: 0.2331 - val_accuracy: 0.9702\n","Epoch 59/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0350 - accuracy: 0.9897 - val_loss: 0.2873 - val_accuracy: 0.9619\n","Epoch 60/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.1995 - val_accuracy: 0.9710\n","Epoch 61/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.9941 - val_loss: 0.2863 - val_accuracy: 0.9694\n","Epoch 62/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0371 - accuracy: 0.9884 - val_loss: 0.2579 - val_accuracy: 0.9698\n","Epoch 63/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.2957 - val_accuracy: 0.9579\n","Epoch 64/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0329 - accuracy: 0.9910 - val_loss: 0.2352 - val_accuracy: 0.9683\n","Epoch 65/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.2291 - val_accuracy: 0.9690\n","Epoch 66/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.2438 - val_accuracy: 0.9706\n","Epoch 67/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0236 - accuracy: 0.9930 - val_loss: 0.2555 - val_accuracy: 0.9710\n","Epoch 68/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.2502 - val_accuracy: 0.9714\n","Epoch 69/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 0.2617 - val_accuracy: 0.9750\n","Epoch 70/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 0.2589 - val_accuracy: 0.9694\n","Epoch 71/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.2243 - val_accuracy: 0.9742\n","Epoch 72/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.2603 - val_accuracy: 0.9679\n","Epoch 73/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.2566 - val_accuracy: 0.9694\n","Epoch 74/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0233 - accuracy: 0.9934 - val_loss: 0.2257 - val_accuracy: 0.9726\n","Epoch 75/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0169 - accuracy: 0.9941 - val_loss: 0.2222 - val_accuracy: 0.9738\n","Epoch 76/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.2528 - val_accuracy: 0.9690\n","Epoch 77/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0282 - accuracy: 0.9919 - val_loss: 0.2508 - val_accuracy: 0.9690\n","Epoch 78/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0183 - accuracy: 0.9954 - val_loss: 0.2656 - val_accuracy: 0.9683\n","Epoch 79/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.2973 - val_accuracy: 0.9718\n","Epoch 80/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.2795 - val_accuracy: 0.9659\n","Epoch 81/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0365 - accuracy: 0.9926 - val_loss: 0.2723 - val_accuracy: 0.9651\n","Epoch 82/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.3337 - val_accuracy: 0.9706\n","Epoch 83/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.2782 - val_accuracy: 0.9643\n","Epoch 84/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.2962 - val_accuracy: 0.9687\n","Epoch 85/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.2481 - val_accuracy: 0.9706\n","Epoch 86/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0252 - accuracy: 0.9943 - val_loss: 0.3164 - val_accuracy: 0.9663\n","Epoch 87/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.3080 - val_accuracy: 0.9710\n","Epoch 88/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.3088 - val_accuracy: 0.9730\n","Epoch 89/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0259 - accuracy: 0.9934 - val_loss: 0.2520 - val_accuracy: 0.9714\n","Epoch 90/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0279 - accuracy: 0.9930 - val_loss: 0.2793 - val_accuracy: 0.9663\n","Epoch 91/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.3032 - val_accuracy: 0.9687\n","Epoch 92/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.2636 - val_accuracy: 0.9722\n","Epoch 93/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0262 - accuracy: 0.9937 - val_loss: 0.2807 - val_accuracy: 0.9694\n","Epoch 94/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.3035 - val_accuracy: 0.9667\n","Epoch 95/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.3220 - val_accuracy: 0.9683\n","Epoch 96/100\n","143/143 [==============================] - 1s 7ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.3611 - val_accuracy: 0.9643\n","Epoch 97/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0285 - accuracy: 0.9932 - val_loss: 0.2799 - val_accuracy: 0.9687\n","Epoch 98/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.2962 - val_accuracy: 0.9675\n","Epoch 99/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0222 - accuracy: 0.9950 - val_loss: 0.3496 - val_accuracy: 0.9667\n","Epoch 100/100\n","143/143 [==============================] - 1s 6ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.3410 - val_accuracy: 0.9683\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4TMxY_pMsm6W","colab_type":"text"},"source":["### 2.0 Now let's try training with 56-56-3 images with more complex models and see whether higher resolution images are more effective"]},{"cell_type":"markdown","metadata":{"id":"v9z0PhtMtU4s","colab_type":"text"},"source":["##### High resolution images need more complex models with more layers in order to enable encoding info into much lower dimensions. So here I tried with 4 sets of Conv+Pooling+Dropout layers with the base model"]},{"cell_type":"markdown","metadata":{"id":"YTLEQ-0RtxdX","colab_type":"text"},"source":["#### The best model with 28-28-3 images gives **98.2%** validation accuracy, while the model with 56-56-3 images results the accuracy of **98.89%**"]},{"cell_type":"code","metadata":{"id":"dx0JAjCRCZAx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598009818010,"user_tz":-120,"elapsed":301948,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"f8e7f6b1-0acd-46a0-d38e-4139b16210d6"},"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(128, (3,3), dilation_rate=2, activation=tf.nn.relu, input_shape=(56, 56, 3)),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.25),\n","    tf.keras.layers.Conv2D(256, (3,3), dilation_rate=1, activation=tf.nn.relu),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.25),\n","    tf.keras.layers.Conv2D(512, (3,3), dilation_rate=1, activation=tf.nn.relu),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.4),  \n","    tf.keras.layers.Conv2D(512, (3,3),  activation=tf.nn.relu),\n","    tf.keras.layers.AveragePooling2D(2,2),\n","    tf.keras.layers.Dropout(0.4),    \n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.25),\n","    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n","   \n","])\n","\n","callbacks = myCallback(0.988)\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","history = model.fit(Trainingimages56, y_train, validation_data=(Testimages56, y_test), \n","          epochs=100, callbacks=[callbacks])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_34\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_42 (Conv2D)           (None, 52, 52, 128)       3584      \n","_________________________________________________________________\n","max_pooling2d_39 (MaxPooling (None, 26, 26, 128)       0         \n","_________________________________________________________________\n","dropout_71 (Dropout)         (None, 26, 26, 128)       0         \n","_________________________________________________________________\n","conv2d_43 (Conv2D)           (None, 24, 24, 256)       295168    \n","_________________________________________________________________\n","max_pooling2d_40 (MaxPooling (None, 12, 12, 256)       0         \n","_________________________________________________________________\n","dropout_72 (Dropout)         (None, 12, 12, 256)       0         \n","_________________________________________________________________\n","conv2d_44 (Conv2D)           (None, 10, 10, 512)       1180160   \n","_________________________________________________________________\n","max_pooling2d_41 (MaxPooling (None, 5, 5, 512)         0         \n","_________________________________________________________________\n","dropout_73 (Dropout)         (None, 5, 5, 512)         0         \n","_________________________________________________________________\n","conv2d_45 (Conv2D)           (None, 3, 3, 512)         2359808   \n","_________________________________________________________________\n","average_pooling2d_3 (Average (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","dropout_74 (Dropout)         (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten_34 (Flatten)         (None, 512)               0         \n","_________________________________________________________________\n","dropout_75 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_68 (Dense)             (None, 512)               262656    \n","_________________________________________________________________\n","dropout_76 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_69 (Dense)             (None, 62)                31806     \n","=================================================================\n","Total params: 4,133,182\n","Trainable params: 4,133,182\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","143/143 [==============================] - 4s 27ms/step - loss: 3.1783 - accuracy: 0.2024 - val_loss: 2.5417 - val_accuracy: 0.3825\n","Epoch 2/100\n","143/143 [==============================] - 4s 25ms/step - loss: 1.8819 - accuracy: 0.4918 - val_loss: 1.4243 - val_accuracy: 0.5837\n","Epoch 3/100\n","143/143 [==============================] - 4s 26ms/step - loss: 1.1452 - accuracy: 0.6772 - val_loss: 0.6554 - val_accuracy: 0.8321\n","Epoch 4/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.8122 - accuracy: 0.7598 - val_loss: 0.4982 - val_accuracy: 0.8635\n","Epoch 5/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.6021 - accuracy: 0.8269 - val_loss: 0.3288 - val_accuracy: 0.9111\n","Epoch 6/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.4555 - accuracy: 0.8654 - val_loss: 0.3117 - val_accuracy: 0.9250\n","Epoch 7/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.3678 - accuracy: 0.8887 - val_loss: 0.2444 - val_accuracy: 0.9353\n","Epoch 8/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.3049 - accuracy: 0.9110 - val_loss: 0.2329 - val_accuracy: 0.9389\n","Epoch 9/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.2862 - accuracy: 0.9102 - val_loss: 0.2308 - val_accuracy: 0.9413\n","Epoch 10/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.2522 - accuracy: 0.9270 - val_loss: 0.2428 - val_accuracy: 0.9448\n","Epoch 11/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.2161 - accuracy: 0.9327 - val_loss: 0.2058 - val_accuracy: 0.9520\n","Epoch 12/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1916 - accuracy: 0.9440 - val_loss: 0.1834 - val_accuracy: 0.9639\n","Epoch 13/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.1680 - accuracy: 0.9495 - val_loss: 0.1896 - val_accuracy: 0.9655\n","Epoch 14/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1580 - accuracy: 0.9528 - val_loss: 0.2301 - val_accuracy: 0.9571\n","Epoch 15/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1646 - accuracy: 0.9532 - val_loss: 0.2077 - val_accuracy: 0.9579\n","Epoch 16/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1897 - accuracy: 0.9454 - val_loss: 0.2544 - val_accuracy: 0.9460\n","Epoch 17/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1468 - accuracy: 0.9556 - val_loss: 0.1558 - val_accuracy: 0.9722\n","Epoch 18/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1242 - accuracy: 0.9650 - val_loss: 0.1716 - val_accuracy: 0.9718\n","Epoch 19/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1020 - accuracy: 0.9685 - val_loss: 0.1986 - val_accuracy: 0.9778\n","Epoch 20/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0959 - accuracy: 0.9711 - val_loss: 0.1602 - val_accuracy: 0.9702\n","Epoch 21/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0958 - accuracy: 0.9698 - val_loss: 0.1895 - val_accuracy: 0.9766\n","Epoch 22/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1006 - accuracy: 0.9701 - val_loss: 0.2182 - val_accuracy: 0.9750\n","Epoch 23/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0870 - accuracy: 0.9764 - val_loss: 0.1633 - val_accuracy: 0.9833\n","Epoch 24/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0927 - accuracy: 0.9714 - val_loss: 0.2722 - val_accuracy: 0.9742\n","Epoch 25/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0882 - accuracy: 0.9744 - val_loss: 0.1633 - val_accuracy: 0.9810\n","Epoch 26/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0727 - accuracy: 0.9786 - val_loss: 0.1893 - val_accuracy: 0.9829\n","Epoch 27/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0844 - accuracy: 0.9751 - val_loss: 0.1742 - val_accuracy: 0.9821\n","Epoch 28/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0846 - accuracy: 0.9786 - val_loss: 0.2090 - val_accuracy: 0.9778\n","Epoch 29/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0978 - accuracy: 0.9757 - val_loss: 0.2053 - val_accuracy: 0.9643\n","Epoch 30/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1018 - accuracy: 0.9725 - val_loss: 0.1831 - val_accuracy: 0.9758\n","Epoch 31/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0620 - accuracy: 0.9840 - val_loss: 0.2246 - val_accuracy: 0.9758\n","Epoch 32/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0920 - accuracy: 0.9768 - val_loss: 0.1971 - val_accuracy: 0.9762\n","Epoch 33/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0719 - accuracy: 0.9766 - val_loss: 0.1805 - val_accuracy: 0.9841\n","Epoch 34/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0593 - accuracy: 0.9819 - val_loss: 0.1692 - val_accuracy: 0.9837\n","Epoch 35/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0680 - accuracy: 0.9808 - val_loss: 0.2029 - val_accuracy: 0.9794\n","Epoch 36/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0775 - accuracy: 0.9795 - val_loss: 0.2199 - val_accuracy: 0.9734\n","Epoch 37/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0751 - accuracy: 0.9814 - val_loss: 0.1879 - val_accuracy: 0.9734\n","Epoch 38/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0806 - accuracy: 0.9792 - val_loss: 0.1513 - val_accuracy: 0.9790\n","Epoch 39/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0590 - accuracy: 0.9821 - val_loss: 0.1816 - val_accuracy: 0.9758\n","Epoch 40/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0810 - accuracy: 0.9784 - val_loss: 0.2063 - val_accuracy: 0.9853\n","Epoch 41/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0458 - accuracy: 0.9864 - val_loss: 0.2084 - val_accuracy: 0.9833\n","Epoch 42/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0753 - accuracy: 0.9825 - val_loss: 0.1834 - val_accuracy: 0.9786\n","Epoch 43/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0892 - accuracy: 0.9762 - val_loss: 0.1986 - val_accuracy: 0.9829\n","Epoch 44/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0675 - accuracy: 0.9819 - val_loss: 0.2057 - val_accuracy: 0.9790\n","Epoch 45/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0466 - accuracy: 0.9880 - val_loss: 0.1907 - val_accuracy: 0.9853\n","Epoch 46/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0365 - accuracy: 0.9902 - val_loss: 0.1775 - val_accuracy: 0.9825\n","Epoch 47/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0412 - accuracy: 0.9893 - val_loss: 0.2215 - val_accuracy: 0.9806\n","Epoch 48/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0451 - accuracy: 0.9873 - val_loss: 0.2124 - val_accuracy: 0.9770\n","Epoch 49/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1360 - accuracy: 0.9731 - val_loss: 0.2206 - val_accuracy: 0.9786\n","Epoch 50/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0709 - accuracy: 0.9810 - val_loss: 0.2140 - val_accuracy: 0.9730\n","Epoch 51/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0633 - accuracy: 0.9816 - val_loss: 0.1843 - val_accuracy: 0.9857\n","Epoch 52/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0459 - accuracy: 0.9869 - val_loss: 0.1683 - val_accuracy: 0.9845\n","Epoch 53/100\n","143/143 [==============================] - 4s 26ms/step - loss: 0.0506 - accuracy: 0.9895 - val_loss: 0.1497 - val_accuracy: 0.9802\n","Epoch 54/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0470 - accuracy: 0.9867 - val_loss: 0.1473 - val_accuracy: 0.9869\n","Epoch 55/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0368 - accuracy: 0.9895 - val_loss: 0.1710 - val_accuracy: 0.9845\n","Epoch 56/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0599 - accuracy: 0.9854 - val_loss: 0.2528 - val_accuracy: 0.9833\n","Epoch 57/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0640 - accuracy: 0.9834 - val_loss: 0.2570 - val_accuracy: 0.9766\n","Epoch 58/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0658 - accuracy: 0.9836 - val_loss: 0.2330 - val_accuracy: 0.9845\n","Epoch 59/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0760 - accuracy: 0.9851 - val_loss: 0.2055 - val_accuracy: 0.9798\n","Epoch 60/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0574 - accuracy: 0.9854 - val_loss: 0.2519 - val_accuracy: 0.9853\n","Epoch 61/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0412 - accuracy: 0.9902 - val_loss: 0.2326 - val_accuracy: 0.9865\n","Epoch 62/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0505 - accuracy: 0.9862 - val_loss: 0.1837 - val_accuracy: 0.9857\n","Epoch 63/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0348 - accuracy: 0.9908 - val_loss: 0.2365 - val_accuracy: 0.9821\n","Epoch 64/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1001 - accuracy: 0.9764 - val_loss: 0.2810 - val_accuracy: 0.9786\n","Epoch 65/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0482 - accuracy: 0.9878 - val_loss: 0.3065 - val_accuracy: 0.9845\n","Epoch 66/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0600 - accuracy: 0.9838 - val_loss: 0.2737 - val_accuracy: 0.9798\n","Epoch 67/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0534 - accuracy: 0.9862 - val_loss: 0.2068 - val_accuracy: 0.9841\n","Epoch 68/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0555 - accuracy: 0.9856 - val_loss: 0.2097 - val_accuracy: 0.9837\n","Epoch 69/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0540 - accuracy: 0.9886 - val_loss: 0.2439 - val_accuracy: 0.9853\n","Epoch 70/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0367 - accuracy: 0.9889 - val_loss: 0.2676 - val_accuracy: 0.9821\n","Epoch 71/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0444 - accuracy: 0.9895 - val_loss: 0.2954 - val_accuracy: 0.9829\n","Epoch 72/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0300 - accuracy: 0.9919 - val_loss: 0.2876 - val_accuracy: 0.9869\n","Epoch 73/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0480 - accuracy: 0.9899 - val_loss: 0.2786 - val_accuracy: 0.9782\n","Epoch 74/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.1019 - accuracy: 0.9786 - val_loss: 0.1828 - val_accuracy: 0.9861\n","Epoch 75/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0445 - accuracy: 0.9871 - val_loss: 0.2527 - val_accuracy: 0.9873\n","Epoch 76/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0272 - accuracy: 0.9932 - val_loss: 0.1696 - val_accuracy: 0.9865\n","Epoch 77/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0465 - accuracy: 0.9889 - val_loss: 0.2989 - val_accuracy: 0.9802\n","Epoch 78/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 0.2355 - val_accuracy: 0.9845\n","Epoch 79/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0552 - accuracy: 0.9858 - val_loss: 0.2131 - val_accuracy: 0.9865\n","Epoch 80/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0675 - accuracy: 0.9847 - val_loss: 0.2025 - val_accuracy: 0.9837\n","Epoch 81/100\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0585 - accuracy: 0.9864 - val_loss: 0.2494 - val_accuracy: 0.9821\n","Epoch 82/100\n","142/143 [============================>.] - ETA: 0s - loss: 0.0598 - accuracy: 0.9875\n","Reached at the expected accuracy level on the validation set, so cancelling training!\n","143/143 [==============================] - 4s 25ms/step - loss: 0.0594 - accuracy: 0.9875 - val_loss: 0.1826 - val_accuracy: 0.9889\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4iPDFh4f4-sV","colab_type":"text"},"source":["===============================================================================\n","## 3.0 Transfer learning\n","#### So far we have seen that high resolution images need more complex models in order to secure convincing accuracy level. However, fine tuning a complex is highly time consuming and challenging. In this case using transfer learning would be a very smart approach. There are lots of highly efficient models and architecture available on *tf-hub*. We can just adopt one or more models with our dataset. \n","\n","Here we will consider the images with 112-112-3 pixels. Many classification architectures on tf-hub do not support this resolution. Here we will see the performance of two well-known models. Other models need very fine resolution.\n","\n","- InceptionNet_v3 \n","- InceptionResNet       \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U-7kvcfh1mKI","colab_type":"text"},"source":["#### 3.1 InceptionNet_v3 gives **99.13%** validation accuracy, InceptionResNet can also result nearly 99% validation accuracy (not shown here)"]},{"cell_type":"code","metadata":{"id":"rYt8vCSux_gW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598011544879,"user_tz":-120,"elapsed":1086608,"user":{"displayName":"Helal Chowdhury","photoUrl":"","userId":"17461430688373646004"}},"outputId":"e3ca10ee-4cb6-4510-e7cc-cd8211d531c4"},"source":["IMAGE_SIZE = (112,112)\n","inceptionNet_HANDLE ='https://tfhub.dev/google/imagenet/inception_v3/classification/4'\n","\n","model = tf.keras.Sequential([\n","        hub.KerasLayer(inceptionNet_HANDLE, input_shape= IMAGE_SIZE + (3,), trainable=True),\n","        #tf.keras.layers.Dropout(.2),\n","        tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n","])\n","\n","callbacks = myCallback(.991)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","history = model.fit(Trainingimages112, y_train, validation_data=(Testimages112, y_test),  epochs=100, callbacks=[callbacks])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","143/143 [==============================] - 16s 110ms/step - loss: 1.8943 - accuracy: 0.7080 - val_loss: 1075.3987 - val_accuracy: 0.0127\n","Epoch 2/100\n","143/143 [==============================] - 13s 93ms/step - loss: 1.2000 - accuracy: 0.8306 - val_loss: 1.2552 - val_accuracy: 0.8389\n","Epoch 3/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.6041 - accuracy: 0.9257 - val_loss: 0.5349 - val_accuracy: 0.9611\n","Epoch 4/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4914 - accuracy: 0.9545 - val_loss: 0.6411 - val_accuracy: 0.9234\n","Epoch 5/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5791 - accuracy: 0.9475 - val_loss: 0.7376 - val_accuracy: 0.9048\n","Epoch 6/100\n","143/143 [==============================] - 13s 92ms/step - loss: 0.5791 - accuracy: 0.9456 - val_loss: 0.9189 - val_accuracy: 0.9409\n","Epoch 7/100\n","143/143 [==============================] - 13s 92ms/step - loss: 0.5049 - accuracy: 0.9574 - val_loss: 0.5192 - val_accuracy: 0.9679\n","Epoch 8/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4302 - accuracy: 0.9720 - val_loss: 0.5710 - val_accuracy: 0.9560\n","Epoch 9/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4041 - accuracy: 0.9821 - val_loss: 0.4446 - val_accuracy: 0.9853\n","Epoch 10/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4196 - accuracy: 0.9742 - val_loss: 0.4245 - val_accuracy: 0.9802\n","Epoch 11/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3806 - accuracy: 0.9854 - val_loss: 0.4333 - val_accuracy: 0.9833\n","Epoch 12/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.6626 - accuracy: 0.9456 - val_loss: 41.4710 - val_accuracy: 0.2179\n","Epoch 13/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5933 - accuracy: 0.9456 - val_loss: 0.8484 - val_accuracy: 0.9163\n","Epoch 14/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4115 - accuracy: 0.9821 - val_loss: 0.5316 - val_accuracy: 0.9635\n","Epoch 15/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4034 - accuracy: 0.9827 - val_loss: 0.6152 - val_accuracy: 0.9377\n","Epoch 16/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5536 - accuracy: 0.9593 - val_loss: 0.5166 - val_accuracy: 0.9714\n","Epoch 17/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4048 - accuracy: 0.9838 - val_loss: 0.4128 - val_accuracy: 0.9909\n","Epoch 18/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3671 - accuracy: 0.9919 - val_loss: 0.4603 - val_accuracy: 0.9802\n","Epoch 19/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3519 - accuracy: 0.9932 - val_loss: 0.4122 - val_accuracy: 0.9877\n","Epoch 20/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3326 - accuracy: 0.9963 - val_loss: 0.4002 - val_accuracy: 0.9905\n","Epoch 21/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3224 - accuracy: 0.9963 - val_loss: 0.4019 - val_accuracy: 0.9893\n","Epoch 22/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3906 - accuracy: 0.9838 - val_loss: 0.7688 - val_accuracy: 0.9313\n","Epoch 23/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.6390 - accuracy: 0.9384 - val_loss: 17.6024 - val_accuracy: 0.2556\n","Epoch 24/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5688 - accuracy: 0.9506 - val_loss: 0.6481 - val_accuracy: 0.9456\n","Epoch 25/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4397 - accuracy: 0.9810 - val_loss: 0.5216 - val_accuracy: 0.9810\n","Epoch 26/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3828 - accuracy: 0.9913 - val_loss: 0.4561 - val_accuracy: 0.9825\n","Epoch 27/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3574 - accuracy: 0.9941 - val_loss: 0.4313 - val_accuracy: 0.9889\n","Epoch 28/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3549 - accuracy: 0.9932 - val_loss: 0.5453 - val_accuracy: 0.9591\n","Epoch 29/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3591 - accuracy: 0.9893 - val_loss: 0.6038 - val_accuracy: 0.9758\n","Epoch 30/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3769 - accuracy: 0.9871 - val_loss: 0.4378 - val_accuracy: 0.9833\n","Epoch 31/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4383 - accuracy: 0.9760 - val_loss: 6.8950 - val_accuracy: 0.5139\n","Epoch 32/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.9101 - accuracy: 0.9244 - val_loss: 14.2158 - val_accuracy: 0.5615\n","Epoch 33/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.7451 - accuracy: 0.9495 - val_loss: 1.4427 - val_accuracy: 0.9123\n","Epoch 34/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4553 - accuracy: 0.9906 - val_loss: 0.5600 - val_accuracy: 0.9813\n","Epoch 35/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4438 - accuracy: 0.9910 - val_loss: 0.5503 - val_accuracy: 0.9806\n","Epoch 36/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4071 - accuracy: 0.9950 - val_loss: 0.5426 - val_accuracy: 0.9869\n","Epoch 37/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4015 - accuracy: 0.9943 - val_loss: 0.6061 - val_accuracy: 0.9750\n","Epoch 38/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4168 - accuracy: 0.9891 - val_loss: 0.5639 - val_accuracy: 0.9627\n","Epoch 39/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4087 - accuracy: 0.9897 - val_loss: 0.5232 - val_accuracy: 0.9778\n","Epoch 40/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4496 - accuracy: 0.9843 - val_loss: 0.5399 - val_accuracy: 0.9762\n","Epoch 41/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3870 - accuracy: 0.9915 - val_loss: 0.5361 - val_accuracy: 0.9758\n","Epoch 42/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4034 - accuracy: 0.9873 - val_loss: 0.4770 - val_accuracy: 0.9782\n","Epoch 43/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3531 - accuracy: 0.9961 - val_loss: 0.4424 - val_accuracy: 0.9841\n","Epoch 44/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3456 - accuracy: 0.9952 - val_loss: 0.4200 - val_accuracy: 0.9873\n","Epoch 45/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3203 - accuracy: 0.9974 - val_loss: 0.3986 - val_accuracy: 0.9861\n","Epoch 46/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3139 - accuracy: 0.9958 - val_loss: 0.4064 - val_accuracy: 0.9837\n","Epoch 47/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.3289 - accuracy: 0.9934 - val_loss: 0.4407 - val_accuracy: 0.9774\n","Epoch 48/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4209 - accuracy: 0.9746 - val_loss: 23.8245 - val_accuracy: 0.6321\n","Epoch 49/100\n","143/143 [==============================] - 13s 93ms/step - loss: 2.4134 - accuracy: 0.8398 - val_loss: 7081.5015 - val_accuracy: 0.0532\n","Epoch 50/100\n","143/143 [==============================] - 13s 93ms/step - loss: 1.0690 - accuracy: 0.9231 - val_loss: 1.0793 - val_accuracy: 0.9393\n","Epoch 51/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.6968 - accuracy: 0.9722 - val_loss: 0.7307 - val_accuracy: 0.9778\n","Epoch 52/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.6179 - accuracy: 0.9843 - val_loss: 0.7204 - val_accuracy: 0.9806\n","Epoch 53/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.6186 - accuracy: 0.9860 - val_loss: 0.7070 - val_accuracy: 0.9778\n","Epoch 54/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.6445 - accuracy: 0.9808 - val_loss: 0.7798 - val_accuracy: 0.9611\n","Epoch 55/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5654 - accuracy: 0.9897 - val_loss: 0.6439 - val_accuracy: 0.9857\n","Epoch 56/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5244 - accuracy: 0.9921 - val_loss: 0.6237 - val_accuracy: 0.9845\n","Epoch 57/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.6066 - accuracy: 0.9895 - val_loss: 1.1215 - val_accuracy: 0.9556\n","Epoch 58/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5434 - accuracy: 0.9878 - val_loss: 0.6066 - val_accuracy: 0.9810\n","Epoch 59/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5335 - accuracy: 0.9882 - val_loss: 2.5045 - val_accuracy: 0.8913\n","Epoch 60/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5132 - accuracy: 0.9908 - val_loss: 0.6101 - val_accuracy: 0.9845\n","Epoch 61/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4680 - accuracy: 0.9958 - val_loss: 0.5960 - val_accuracy: 0.9849\n","Epoch 62/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5747 - accuracy: 0.9832 - val_loss: 127.7484 - val_accuracy: 0.7385\n","Epoch 63/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.6402 - accuracy: 0.9733 - val_loss: 1.0136 - val_accuracy: 0.9516\n","Epoch 64/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5592 - accuracy: 0.9825 - val_loss: 0.7677 - val_accuracy: 0.9496\n","Epoch 65/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.7743 - accuracy: 0.9718 - val_loss: 1.3708 - val_accuracy: 0.8948\n","Epoch 66/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5976 - accuracy: 0.9816 - val_loss: 0.6307 - val_accuracy: 0.9766\n","Epoch 67/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5594 - accuracy: 0.9902 - val_loss: 0.6315 - val_accuracy: 0.9853\n","Epoch 68/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.6786 - accuracy: 0.9775 - val_loss: 2.5310 - val_accuracy: 0.8183\n","Epoch 69/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5769 - accuracy: 0.9867 - val_loss: 0.9962 - val_accuracy: 0.9591\n","Epoch 70/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5116 - accuracy: 0.9954 - val_loss: 0.6179 - val_accuracy: 0.9857\n","Epoch 71/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4776 - accuracy: 0.9969 - val_loss: 0.5759 - val_accuracy: 0.9873\n","Epoch 72/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4528 - accuracy: 0.9985 - val_loss: 0.6714 - val_accuracy: 0.9671\n","Epoch 73/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4514 - accuracy: 0.9956 - val_loss: 0.6026 - val_accuracy: 0.9829\n","Epoch 74/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4753 - accuracy: 0.9908 - val_loss: 0.6240 - val_accuracy: 0.9722\n","Epoch 75/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4345 - accuracy: 0.9928 - val_loss: 0.5388 - val_accuracy: 0.9790\n","Epoch 76/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.4775 - accuracy: 0.9856 - val_loss: 0.6042 - val_accuracy: 0.9702\n","Epoch 77/100\n","143/143 [==============================] - 13s 93ms/step - loss: 0.7964 - accuracy: 0.9631 - val_loss: 19901.9004 - val_accuracy: 0.0417\n","Epoch 78/100\n","143/143 [==============================] - 13s 92ms/step - loss: 1.2855 - accuracy: 0.9263 - val_loss: 0.9446 - val_accuracy: 0.9365\n","Epoch 79/100\n","143/143 [==============================] - 13s 92ms/step - loss: 0.6532 - accuracy: 0.9821 - val_loss: 0.6906 - val_accuracy: 0.9845\n","Epoch 80/100\n","143/143 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.9945\n","Reached at the expected accuracy level on the validation set, so cancelling training!\n","143/143 [==============================] - 13s 93ms/step - loss: 0.5636 - accuracy: 0.9945 - val_loss: 0.6423 - val_accuracy: 0.9913\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sUYvhzkGMiDs","colab_type":"text"},"source":["### 4.0 Summary\n","\n","In this notebook, various convolutional techniques have been applied to BelgianTS dataset for classification with 62 classes. How to develop a convincing model with excellent accuracy (e.g. 99% or higher) has been demonstrated here. What we have learnt so far:\n","\n","- If we want faster training with nearly very good accuracy, training with gray images are OK\n","- RGB images gives slightly higher accuracy than that of gray images\n","- Lower resolution RGB images can give very good accuracy if the NN architecture and hyperparameters are well-tuned\n","- High resolution images can give slightly better accuracy than that of low resolution, however, CNN architecture for high quality images would be more and more complex depending on resolution, and the training time would be gradually higher. The process of fine tuning a compex model is highly time consuming\n","- A very smart approach in this case would be the idea of transfer learning, using a state-of-the-art model like ResNet, InceptionNet etc. A suitable model in this case generally can give excellent accuracy."]}]}