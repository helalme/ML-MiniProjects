{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belgian Traffic Signs Classification \n",
    "\n",
    "The dataset of BelgianTS is wellknown and probably it has various versions with different sizes. Here I used the dataset that contains 62 classes of images with 4575 images for training and 2520 for validation.\n",
    "\n",
    "Some of simplified models have been used step by step to check the validation set accuracy. A simple 2 layers feed-forward NN model shows 93.89% accuracy, while an addition of one Conv2D+MaxPooling2D gives 95.3% accuracy.\n",
    "\n",
    "Two pairs of Conv2D+MaxPooling2D alon with two Dense layers helps to achieve 97% validation accuracy. At the end we see that the accuracy increases to 97.8% when we add Dropout layer after each MaxPooling.\n",
    "\n",
    "One observation for this dataset is: grey scale images results in faster training, whereas RGB images give higher accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import data\n",
    "#from skimage.viewer import ImageViewer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below three cells are related to ETL process of data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_directory):\n",
    "    directories = [d for d in os.listdir(data_directory) \n",
    "                   if os.path.isdir(os.path.join(data_directory, d))]\n",
    "    labels = []\n",
    "    images = []\n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(data_directory, d)\n",
    "        file_names = [os.path.join(label_directory, f) \n",
    "                      for f in os.listdir(label_directory) \n",
    "                      if f.endswith(\".ppm\")]\n",
    "        for f in file_names:\n",
    "            images.append(data.imread(f)) #skimage theke data import kore imread() call kora hoise \n",
    "            labels.append(int(d))\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_data_directory = os.path.join(cwd, \"Training\")\n",
    "test_data_directory = os.path.join(cwd, \"Testing\")\n",
    "\n",
    "x_train, y_train = load_data(train_data_directory)\n",
    "x_test, y_test = load_data(test_data_directory)\n",
    "\n",
    "#callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "Trainimages = [transform.resize(image, (28, 28)) for image in x_train]\n",
    "Trainimages = np.array(Trainimages)\n",
    "#Trainimages = rgb2gray(Trainimages)\n",
    "\n",
    "Testimages = [transform.resize(image, (28, 28)) for image in x_test]\n",
    "Testimages = np.array(Testimages)\n",
    "#Testimages = rgb2gray(Testimages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The siplest model with two dense layers, Validation accurcy = 93.89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4575 samples, validate on 2520 samples\n",
      "Epoch 1/100\n",
      "4575/4575 [==============================] - 3s 648us/sample - loss: 2.1950 - accuracy: 0.5128 - val_loss: 1.4593 - val_accuracy: 0.6762\n",
      "Epoch 2/100\n",
      "4575/4575 [==============================] - 2s 518us/sample - loss: 1.0671 - accuracy: 0.7534 - val_loss: 0.9799 - val_accuracy: 0.7762\n",
      "Epoch 3/100\n",
      "4575/4575 [==============================] - 2s 491us/sample - loss: 0.7245 - accuracy: 0.8345 - val_loss: 0.8533 - val_accuracy: 0.7639\n",
      "Epoch 4/100\n",
      "4575/4575 [==============================] - 2s 498us/sample - loss: 0.5326 - accuracy: 0.8748 - val_loss: 0.6038 - val_accuracy: 0.8385\n",
      "Epoch 5/100\n",
      "4575/4575 [==============================] - 2s 481us/sample - loss: 0.4025 - accuracy: 0.9104 - val_loss: 0.5286 - val_accuracy: 0.8508\n",
      "Epoch 6/100\n",
      "4575/4575 [==============================] - 2s 430us/sample - loss: 0.3227 - accuracy: 0.9329 - val_loss: 0.5336 - val_accuracy: 0.8381\n",
      "Epoch 7/100\n",
      "4575/4575 [==============================] - 2s 437us/sample - loss: 0.2696 - accuracy: 0.9436 - val_loss: 0.4899 - val_accuracy: 0.8619\n",
      "Epoch 8/100\n",
      "4575/4575 [==============================] - 2s 414us/sample - loss: 0.2238 - accuracy: 0.9530 - val_loss: 0.4000 - val_accuracy: 0.8948\n",
      "Epoch 9/100\n",
      "4575/4575 [==============================] - 2s 413us/sample - loss: 0.1815 - accuracy: 0.9670 - val_loss: 0.4067 - val_accuracy: 0.8925\n",
      "Epoch 10/100\n",
      "4575/4575 [==============================] - 2s 407us/sample - loss: 0.1638 - accuracy: 0.9666 - val_loss: 0.4529 - val_accuracy: 0.8738\n",
      "Epoch 11/100\n",
      "4575/4575 [==============================] - 2s 413us/sample - loss: 0.1359 - accuracy: 0.9738 - val_loss: 0.4525 - val_accuracy: 0.8679\n",
      "Epoch 12/100\n",
      "4575/4575 [==============================] - 2s 409us/sample - loss: 0.1193 - accuracy: 0.9770 - val_loss: 0.3600 - val_accuracy: 0.9079\n",
      "Epoch 13/100\n",
      "4575/4575 [==============================] - 2s 415us/sample - loss: 0.1007 - accuracy: 0.9805 - val_loss: 0.4348 - val_accuracy: 0.8671\n",
      "Epoch 14/100\n",
      "4575/4575 [==============================] - 2s 412us/sample - loss: 0.1043 - accuracy: 0.9797 - val_loss: 0.4228 - val_accuracy: 0.8790\n",
      "Epoch 15/100\n",
      "4575/4575 [==============================] - 2s 413us/sample - loss: 0.0949 - accuracy: 0.9786 - val_loss: 0.3792 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "4575/4575 [==============================] - 2s 420us/sample - loss: 0.1218 - accuracy: 0.9753 - val_loss: 0.3423 - val_accuracy: 0.9079\n",
      "Epoch 17/100\n",
      "4575/4575 [==============================] - 2s 414us/sample - loss: 0.0589 - accuracy: 0.9906 - val_loss: 0.3349 - val_accuracy: 0.9159\n",
      "Epoch 18/100\n",
      "4575/4575 [==============================] - 2s 430us/sample - loss: 0.0877 - accuracy: 0.9803 - val_loss: 0.3675 - val_accuracy: 0.8905\n",
      "Epoch 19/100\n",
      "4575/4575 [==============================] - 2s 428us/sample - loss: 0.0565 - accuracy: 0.9886 - val_loss: 0.3781 - val_accuracy: 0.9071\n",
      "Epoch 20/100\n",
      "4575/4575 [==============================] - 2s 445us/sample - loss: 0.0456 - accuracy: 0.9910 - val_loss: 0.3518 - val_accuracy: 0.9111\n",
      "Epoch 21/100\n",
      "4575/4575 [==============================] - 2s 411us/sample - loss: 0.0631 - accuracy: 0.9858 - val_loss: 0.3138 - val_accuracy: 0.9214\n",
      "Epoch 22/100\n",
      "4575/4575 [==============================] - 2s 413us/sample - loss: 0.0353 - accuracy: 0.9943 - val_loss: 0.3360 - val_accuracy: 0.9155\n",
      "Epoch 23/100\n",
      "4575/4575 [==============================] - 2s 405us/sample - loss: 0.0527 - accuracy: 0.9904 - val_loss: 0.3340 - val_accuracy: 0.9183\n",
      "Epoch 24/100\n",
      "4575/4575 [==============================] - 2s 427us/sample - loss: 0.0478 - accuracy: 0.9889 - val_loss: 0.4196 - val_accuracy: 0.8929\n",
      "Epoch 25/100\n",
      "4575/4575 [==============================] - 2s 446us/sample - loss: 0.1352 - accuracy: 0.9613 - val_loss: 0.4356 - val_accuracy: 0.8988\n",
      "Epoch 26/100\n",
      "4575/4575 [==============================] - 2s 418us/sample - loss: 0.0624 - accuracy: 0.9851 - val_loss: 0.4520 - val_accuracy: 0.8861\n",
      "Epoch 27/100\n",
      "4575/4575 [==============================] - 2s 448us/sample - loss: 0.0350 - accuracy: 0.9941 - val_loss: 0.3627 - val_accuracy: 0.9107\n",
      "Epoch 28/100\n",
      "4575/4575 [==============================] - 2s 437us/sample - loss: 0.0242 - accuracy: 0.9956 - val_loss: 0.3159 - val_accuracy: 0.9270\n",
      "Epoch 29/100\n",
      "4575/4575 [==============================] - 2s 430us/sample - loss: 0.0213 - accuracy: 0.9950 - val_loss: 0.3299 - val_accuracy: 0.9250\n",
      "Epoch 30/100\n",
      "4575/4575 [==============================] - 2s 428us/sample - loss: 0.0197 - accuracy: 0.9963 - val_loss: 0.3288 - val_accuracy: 0.9218\n",
      "Epoch 31/100\n",
      "4575/4575 [==============================] - 2s 453us/sample - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.3550 - val_accuracy: 0.9230\n",
      "Epoch 32/100\n",
      "4575/4575 [==============================] - 2s 451us/sample - loss: 0.0115 - accuracy: 0.9980 - val_loss: 0.3663 - val_accuracy: 0.9131\n",
      "Epoch 33/100\n",
      "4575/4575 [==============================] - 2s 430us/sample - loss: 0.0117 - accuracy: 0.9978 - val_loss: 0.4163 - val_accuracy: 0.9020\n",
      "Epoch 34/100\n",
      "4575/4575 [==============================] - 2s 444us/sample - loss: 0.0413 - accuracy: 0.9908 - val_loss: 0.6958 - val_accuracy: 0.8552\n",
      "Epoch 35/100\n",
      "4575/4575 [==============================] - 2s 417us/sample - loss: 0.1783 - accuracy: 0.9534 - val_loss: 0.7234 - val_accuracy: 0.8385\n",
      "Epoch 36/100\n",
      "4575/4575 [==============================] - 2s 408us/sample - loss: 0.0788 - accuracy: 0.9790 - val_loss: 0.4718 - val_accuracy: 0.8865\n",
      "Epoch 37/100\n",
      "4575/4575 [==============================] - 2s 417us/sample - loss: 0.0407 - accuracy: 0.9906 - val_loss: 0.3314 - val_accuracy: 0.9258\n",
      "Epoch 38/100\n",
      "4575/4575 [==============================] - 2s 427us/sample - loss: 0.0117 - accuracy: 0.9989 - val_loss: 0.3201 - val_accuracy: 0.9294\n",
      "Epoch 39/100\n",
      "4575/4575 [==============================] - 2s 408us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 0.9270\n",
      "Epoch 40/100\n",
      "4575/4575 [==============================] - 2s 419us/sample - loss: 0.0067 - accuracy: 0.9993 - val_loss: 0.3747 - val_accuracy: 0.9087\n",
      "Epoch 41/100\n",
      "4575/4575 [==============================] - 2s 403us/sample - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.3285 - val_accuracy: 0.9290\n",
      "Epoch 42/100\n",
      "4575/4575 [==============================] - 2s 411us/sample - loss: 0.0286 - accuracy: 0.9952 - val_loss: 0.4904 - val_accuracy: 0.8857\n",
      "Epoch 43/100\n",
      "4575/4575 [==============================] - 2s 410us/sample - loss: 0.1090 - accuracy: 0.9696 - val_loss: 0.5653 - val_accuracy: 0.8770\n",
      "Epoch 44/100\n",
      "4575/4575 [==============================] - 2s 430us/sample - loss: 0.0529 - accuracy: 0.9858 - val_loss: 0.3535 - val_accuracy: 0.9270\n",
      "Epoch 45/100\n",
      "4575/4575 [==============================] - 2s 428us/sample - loss: 0.0173 - accuracy: 0.9967 - val_loss: 0.4232 - val_accuracy: 0.9103\n",
      "Epoch 46/100\n",
      "4512/4575 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9962 ETA: 0s - loss: 0.0165 - accuracy: \n",
      "Reached 93.5% accuracy on test set, so cancelling training!\n",
      "4575/4575 [==============================] - 2s 411us/sample - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.2944 - val_accuracy: 0.9389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230b8d58b08>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_accuracy')>0.935):\n",
    "      print(\"\\nReached 93.5% accuracy on test set, so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28,3)),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n",
    "\n",
    "])\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(np.array(Trainimages), np.array(y_train), validation_data=(Testimages, np.array(y_test)), \n",
    "          epochs=100, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with one pair of Conv2D+MaxPooling2D  along with two Dense layers, Validation accurcy = 95.3%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               2769152   \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 62)                15934     \n",
      "=================================================================\n",
      "Total params: 2,786,878\n",
      "Trainable params: 2,786,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4575 samples, validate on 2520 samples\n",
      "Epoch 1/100\n",
      "4575/4575 [==============================] - 15s 3ms/sample - loss: 1.7070 - accuracy: 0.6310 - val_loss: 0.9301 - val_accuracy: 0.7389\n",
      "Epoch 2/100\n",
      "4575/4575 [==============================] - 15s 3ms/sample - loss: 0.4344 - accuracy: 0.9054 - val_loss: 0.3808 - val_accuracy: 0.9071\n",
      "Epoch 3/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 0.1597 - accuracy: 0.9679 - val_loss: 0.3657 - val_accuracy: 0.8992\n",
      "Epoch 4/100\n",
      "4575/4575 [==============================] - 16s 4ms/sample - loss: 0.0877 - accuracy: 0.9810 - val_loss: 0.2891 - val_accuracy: 0.9226\n",
      "Epoch 5/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0496 - accuracy: 0.9902 - val_loss: 0.2782 - val_accuracy: 0.9270\n",
      "Epoch 6/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 0.0357 - accuracy: 0.9934 - val_loss: 0.2858 - val_accuracy: 0.9175\n",
      "Epoch 7/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0205 - accuracy: 0.9958 - val_loss: 0.2849 - val_accuracy: 0.9278\n",
      "Epoch 8/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 0.0229 - accuracy: 0.9954 - val_loss: 0.2650 - val_accuracy: 0.9321\n",
      "Epoch 9/100\n",
      "4575/4575 [==============================] - 15s 3ms/sample - loss: 0.0101 - accuracy: 0.9987 - val_loss: 0.2433 - val_accuracy: 0.9385\n",
      "Epoch 10/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0186 - accuracy: 0.9958 - val_loss: 0.2718 - val_accuracy: 0.9313\n",
      "Epoch 11/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.2394 - val_accuracy: 0.9409\n",
      "Epoch 12/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.2697 - val_accuracy: 0.9325\n",
      "Epoch 13/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.2980 - val_accuracy: 0.9270\n",
      "Epoch 14/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.3654 - val_accuracy: 0.9107\n",
      "Epoch 15/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.2748 - val_accuracy: 0.9369\n",
      "Epoch 16/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9321\n",
      "Epoch 17/100\n",
      "4575/4575 [==============================] - 15s 3ms/sample - loss: 7.8971e-04 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9349\n",
      "Epoch 18/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 6.6848e-04 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9341\n",
      "Epoch 19/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 5.9267e-04 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9325\n",
      "Epoch 20/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 5.1508e-04 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9349\n",
      "Epoch 21/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 4.3674e-04 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9317\n",
      "Epoch 22/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 4.0362e-04 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9321\n",
      "Epoch 23/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 3.5791e-04 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9369\n",
      "Epoch 24/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 3.1248e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9337\n",
      "Epoch 25/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 2.8775e-04 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.9313\n",
      "Epoch 26/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 2.5413e-04 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.9306\n",
      "Epoch 27/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 2.3660e-04 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9337\n",
      "Epoch 28/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 2.0891e-04 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9337\n",
      "Epoch 29/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 1.9115e-04 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.9321\n",
      "Epoch 30/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 1.7592e-04 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.9357\n",
      "Epoch 31/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 1.5956e-04 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9349\n",
      "Epoch 32/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 1.4355e-04 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9337\n",
      "Epoch 33/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 1.3012e-04 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9313\n",
      "Epoch 34/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 1.2132e-04 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9313\n",
      "Epoch 35/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 1.0816e-04 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9313\n",
      "Epoch 36/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 1.0022e-04 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9333\n",
      "Epoch 37/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 8.9182e-05 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9333\n",
      "Epoch 38/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 8.1720e-05 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9325\n",
      "Epoch 39/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 7.4626e-05 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9337\n",
      "Epoch 40/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 7.0754e-05 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9329\n",
      "Epoch 41/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 6.4290e-05 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9337\n",
      "Epoch 42/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 5.6558e-05 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9325\n",
      "Epoch 43/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 5.3556e-05 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.9321\n",
      "Epoch 44/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.1927 - accuracy: 0.9552 - val_loss: 0.4491 - val_accuracy: 0.8992\n",
      "Epoch 45/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0537 - accuracy: 0.9838 - val_loss: 0.2887 - val_accuracy: 0.9433\n",
      "Epoch 46/100\n",
      "4575/4575 [==============================] - 14s 3ms/sample - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.3177 - val_accuracy: 0.9452\n",
      "Epoch 47/100\n",
      "4544/4575 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Reached 96% accuracy on test set, so cancelling training!\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230bf60ab08>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_accuracy')>=0.95):\n",
    "      print(\"\\nReached 96% accuracy on test set, so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, input_shape=(28, 28, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n",
    "\n",
    "])\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(np.array(Trainimages), np.array(y_train), validation_data=(Testimages, np.array(y_test)), \n",
    "          epochs=100, callbacks=[callbacks])\n",
    "\n",
    "#model.evaluate(np.array(Testimages), np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with two pair of Conv2D+MaxPooling2D along with two Dense layers, Validation accurcy = 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 256)               409856    \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 62)                15934     \n",
      "=================================================================\n",
      "Total params: 464,510\n",
      "Trainable params: 464,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4575 samples, validate on 2520 samples\n",
      "Epoch 1/100\n",
      "4575/4575 [==============================] - 20s 4ms/sample - loss: 1.9414 - accuracy: 0.5628 - val_loss: 0.9059 - val_accuracy: 0.7671\n",
      "Epoch 2/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.5586 - accuracy: 0.8689 - val_loss: 0.5404 - val_accuracy: 0.8667\n",
      "Epoch 3/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.2575 - accuracy: 0.9364 - val_loss: 0.4186 - val_accuracy: 0.8857\n",
      "Epoch 4/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.1439 - accuracy: 0.9617 - val_loss: 0.2406 - val_accuracy: 0.9440\n",
      "Epoch 5/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0800 - accuracy: 0.9810 - val_loss: 0.2564 - val_accuracy: 0.9357\n",
      "Epoch 6/100\n",
      "4575/4575 [==============================] - 11s 3ms/sample - loss: 0.0575 - accuracy: 0.9856 - val_loss: 0.1899 - val_accuracy: 0.9528\n",
      "Epoch 7/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0475 - accuracy: 0.9878 - val_loss: 0.2253 - val_accuracy: 0.9464\n",
      "Epoch 8/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0370 - accuracy: 0.9915 - val_loss: 0.2053 - val_accuracy: 0.9480\n",
      "Epoch 9/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0370 - accuracy: 0.9906 - val_loss: 0.2080 - val_accuracy: 0.9544\n",
      "Epoch 10/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0529 - accuracy: 0.9871 - val_loss: 0.2029 - val_accuracy: 0.9560\n",
      "Epoch 11/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0151 - accuracy: 0.9961 - val_loss: 0.1915 - val_accuracy: 0.9619\n",
      "Epoch 12/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.1897 - val_accuracy: 0.9556\n",
      "Epoch 13/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.2638 - val_accuracy: 0.9488\n",
      "Epoch 14/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.2261 - val_accuracy: 0.9528\n",
      "Epoch 15/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.2091 - val_accuracy: 0.9595\n",
      "Epoch 16/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2039 - val_accuracy: 0.9603\n",
      "Epoch 17/100\n",
      "4575/4575 [==============================] - 11s 3ms/sample - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.2676 - val_accuracy: 0.9429\n",
      "Epoch 18/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0372 - accuracy: 0.9906 - val_loss: 0.3250 - val_accuracy: 0.9242\n",
      "Epoch 19/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0722 - accuracy: 0.9801 - val_loss: 0.3343 - val_accuracy: 0.9310\n",
      "Epoch 20/100\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0464 - accuracy: 0.9884 - val_loss: 0.2566 - val_accuracy: 0.9417\n",
      "Epoch 21/100\n",
      "4544/4575 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9993\n",
      "Reached 96.7% accuracy on test set, so cancelling training!\n",
      "4575/4575 [==============================] - 11s 2ms/sample - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.1861 - val_accuracy: 0.9706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230c97b51c8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_accuracy')>0.97):\n",
    "      print(\"\\nReached 97% accuracy on test set, so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "        \n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, input_shape=(28, 28, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n",
    "\n",
    "])\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(Trainimages, np.array(y_train),validation_data=(Testimages, np.array(y_test)),  epochs=100, callbacks=[callbacks])\n",
    "\n",
    "#model.evaluate(Testimages, np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with two sets of Conv2D+MaxPooling2D+Dropout layers along with two Dense layers, Validation accurcy = 97.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 256)               409856    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 62)                15934     \n",
      "=================================================================\n",
      "Total params: 464,510\n",
      "Trainable params: 464,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4575 samples, validate on 2520 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 2.9608 - accuracy: 0.2920 - val_loss: 2.2750 - val_accuracy: 0.4675\n",
      "Epoch 2/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 1.5767 - accuracy: 0.5738 - val_loss: 1.1584 - val_accuracy: 0.7183\n",
      "Epoch 3/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.9995 - accuracy: 0.7217 - val_loss: 0.6897 - val_accuracy: 0.7937\n",
      "Epoch 4/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.7237 - accuracy: 0.7941 - val_loss: 0.5547 - val_accuracy: 0.8992\n",
      "Epoch 5/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.5415 - accuracy: 0.8374 - val_loss: 0.3703 - val_accuracy: 0.9286\n",
      "Epoch 6/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.4452 - accuracy: 0.8603 - val_loss: 0.2998 - val_accuracy: 0.9298\n",
      "Epoch 7/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.3950 - accuracy: 0.8813 - val_loss: 0.3043 - val_accuracy: 0.9373\n",
      "Epoch 8/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.3356 - accuracy: 0.8984 - val_loss: 0.2216 - val_accuracy: 0.9460\n",
      "Epoch 9/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.2987 - accuracy: 0.9086 - val_loss: 0.2083 - val_accuracy: 0.9595\n",
      "Epoch 10/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.2554 - accuracy: 0.9224 - val_loss: 0.1740 - val_accuracy: 0.9623\n",
      "Epoch 11/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.2362 - accuracy: 0.9268 - val_loss: 0.1646 - val_accuracy: 0.9619\n",
      "Epoch 12/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.2053 - accuracy: 0.9351 - val_loss: 0.1491 - val_accuracy: 0.9698\n",
      "Epoch 13/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.2081 - accuracy: 0.9338 - val_loss: 0.1627 - val_accuracy: 0.9643\n",
      "Epoch 14/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1810 - accuracy: 0.9454 - val_loss: 0.1390 - val_accuracy: 0.9687\n",
      "Epoch 15/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1803 - accuracy: 0.9447 - val_loss: 0.1581 - val_accuracy: 0.9615\n",
      "Epoch 16/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1711 - accuracy: 0.9427 - val_loss: 0.1449 - val_accuracy: 0.9714\n",
      "Epoch 17/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1614 - accuracy: 0.9497 - val_loss: 0.1325 - val_accuracy: 0.9698\n",
      "Epoch 18/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1426 - accuracy: 0.9539 - val_loss: 0.1411 - val_accuracy: 0.9659\n",
      "Epoch 19/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1296 - accuracy: 0.9585 - val_loss: 0.1453 - val_accuracy: 0.9690\n",
      "Epoch 20/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1399 - accuracy: 0.9534 - val_loss: 0.1265 - val_accuracy: 0.9702\n",
      "Epoch 21/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1211 - accuracy: 0.9596 - val_loss: 0.1304 - val_accuracy: 0.9706\n",
      "Epoch 22/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1387 - accuracy: 0.9519 - val_loss: 0.1477 - val_accuracy: 0.9671\n",
      "Epoch 23/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1195 - accuracy: 0.9607 - val_loss: 0.1340 - val_accuracy: 0.9690\n",
      "Epoch 24/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.1169 - accuracy: 0.9639 - val_loss: 0.1254 - val_accuracy: 0.9714\n",
      "Epoch 25/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.1204 - accuracy: 0.9611 - val_loss: 0.1344 - val_accuracy: 0.9663\n",
      "Epoch 26/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1136 - accuracy: 0.9620 - val_loss: 0.1432 - val_accuracy: 0.9655\n",
      "Epoch 27/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1118 - accuracy: 0.9635 - val_loss: 0.1297 - val_accuracy: 0.9706\n",
      "Epoch 28/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.1192 - accuracy: 0.9615 - val_loss: 0.1337 - val_accuracy: 0.9687\n",
      "Epoch 29/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.1114 - accuracy: 0.9615 - val_loss: 0.1292 - val_accuracy: 0.9671\n",
      "Epoch 30/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1066 - accuracy: 0.9655 - val_loss: 0.1335 - val_accuracy: 0.9683\n",
      "Epoch 31/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.1038 - accuracy: 0.9655 - val_loss: 0.1586 - val_accuracy: 0.9643\n",
      "Epoch 32/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1063 - accuracy: 0.9677 - val_loss: 0.1379 - val_accuracy: 0.9683\n",
      "Epoch 33/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0970 - accuracy: 0.9707 - val_loss: 0.1424 - val_accuracy: 0.9690\n",
      "Epoch 34/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0832 - accuracy: 0.9753 - val_loss: 0.1217 - val_accuracy: 0.9726\n",
      "Epoch 35/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0948 - accuracy: 0.9677 - val_loss: 0.1302 - val_accuracy: 0.9730\n",
      "Epoch 36/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0953 - accuracy: 0.9709 - val_loss: 0.1292 - val_accuracy: 0.9726\n",
      "Epoch 37/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.1053 - accuracy: 0.9635 - val_loss: 0.1476 - val_accuracy: 0.9639\n",
      "Epoch 38/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0967 - accuracy: 0.9694 - val_loss: 0.1508 - val_accuracy: 0.9667\n",
      "Epoch 39/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0850 - accuracy: 0.9733 - val_loss: 0.1549 - val_accuracy: 0.9667\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0878 - accuracy: 0.9727 - val_loss: 0.1452 - val_accuracy: 0.9651\n",
      "Epoch 41/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0823 - accuracy: 0.9711 - val_loss: 0.1692 - val_accuracy: 0.9615\n",
      "Epoch 42/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0840 - accuracy: 0.9722 - val_loss: 0.1356 - val_accuracy: 0.9690\n",
      "Epoch 43/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0889 - accuracy: 0.9733 - val_loss: 0.1454 - val_accuracy: 0.9663\n",
      "Epoch 44/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0875 - accuracy: 0.9729 - val_loss: 0.1437 - val_accuracy: 0.9683\n",
      "Epoch 45/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0877 - accuracy: 0.9711 - val_loss: 0.1535 - val_accuracy: 0.9663\n",
      "Epoch 46/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0923 - accuracy: 0.9725 - val_loss: 0.1319 - val_accuracy: 0.9726\n",
      "Epoch 47/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0902 - accuracy: 0.9714 - val_loss: 0.1410 - val_accuracy: 0.9663\n",
      "Epoch 48/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0705 - accuracy: 0.9753 - val_loss: 0.1357 - val_accuracy: 0.9718\n",
      "Epoch 49/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0796 - accuracy: 0.9716 - val_loss: 0.1555 - val_accuracy: 0.9671\n",
      "Epoch 50/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0945 - accuracy: 0.9738 - val_loss: 0.1374 - val_accuracy: 0.9750\n",
      "Epoch 51/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.1419 - val_accuracy: 0.9683\n",
      "Epoch 52/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0807 - accuracy: 0.9760 - val_loss: 0.1232 - val_accuracy: 0.9742\n",
      "Epoch 53/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0653 - accuracy: 0.9788 - val_loss: 0.1296 - val_accuracy: 0.9694\n",
      "Epoch 54/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0836 - accuracy: 0.9725 - val_loss: 0.1399 - val_accuracy: 0.9702\n",
      "Epoch 55/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0817 - accuracy: 0.9751 - val_loss: 0.1380 - val_accuracy: 0.9722\n",
      "Epoch 56/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0718 - accuracy: 0.9757 - val_loss: 0.1240 - val_accuracy: 0.9738\n",
      "Epoch 57/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0661 - accuracy: 0.9779 - val_loss: 0.1433 - val_accuracy: 0.9730\n",
      "Epoch 58/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0599 - accuracy: 0.9799 - val_loss: 0.1339 - val_accuracy: 0.9714\n",
      "Epoch 59/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0788 - accuracy: 0.9755 - val_loss: 0.1364 - val_accuracy: 0.9683\n",
      "Epoch 60/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0809 - accuracy: 0.9746 - val_loss: 0.1333 - val_accuracy: 0.9698\n",
      "Epoch 61/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0648 - accuracy: 0.9755 - val_loss: 0.1494 - val_accuracy: 0.9675\n",
      "Epoch 62/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0756 - accuracy: 0.9755 - val_loss: 0.1376 - val_accuracy: 0.9698\n",
      "Epoch 63/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0784 - accuracy: 0.9760 - val_loss: 0.1421 - val_accuracy: 0.9710\n",
      "Epoch 64/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0621 - accuracy: 0.9777 - val_loss: 0.1523 - val_accuracy: 0.9667\n",
      "Epoch 65/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0806 - accuracy: 0.9766 - val_loss: 0.1383 - val_accuracy: 0.9687\n",
      "Epoch 66/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0732 - accuracy: 0.9760 - val_loss: 0.1670 - val_accuracy: 0.9690\n",
      "Epoch 67/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0707 - accuracy: 0.9799 - val_loss: 0.1482 - val_accuracy: 0.9698\n",
      "Epoch 68/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0639 - accuracy: 0.9803 - val_loss: 0.1443 - val_accuracy: 0.9702\n",
      "Epoch 69/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0582 - accuracy: 0.9823 - val_loss: 0.1459 - val_accuracy: 0.9687\n",
      "Epoch 70/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0595 - accuracy: 0.9786 - val_loss: 0.1490 - val_accuracy: 0.9710\n",
      "Epoch 71/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0760 - accuracy: 0.9770 - val_loss: 0.1436 - val_accuracy: 0.9706\n",
      "Epoch 72/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0685 - accuracy: 0.9773 - val_loss: 0.1443 - val_accuracy: 0.9706\n",
      "Epoch 73/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0519 - accuracy: 0.9834 - val_loss: 0.1862 - val_accuracy: 0.9639\n",
      "Epoch 74/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0550 - accuracy: 0.9840 - val_loss: 0.1464 - val_accuracy: 0.9679\n",
      "Epoch 75/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0636 - accuracy: 0.9792 - val_loss: 0.1386 - val_accuracy: 0.9718\n",
      "Epoch 76/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0797 - accuracy: 0.9740 - val_loss: 0.1429 - val_accuracy: 0.9722\n",
      "Epoch 77/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0703 - accuracy: 0.9790 - val_loss: 0.1517 - val_accuracy: 0.9706\n",
      "Epoch 78/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.1621 - val_accuracy: 0.9706\n",
      "Epoch 79/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0576 - accuracy: 0.9786 - val_loss: 0.1522 - val_accuracy: 0.9698\n",
      "Epoch 80/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0640 - accuracy: 0.9803 - val_loss: 0.1575 - val_accuracy: 0.9706\n",
      "Epoch 81/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0510 - accuracy: 0.9849 - val_loss: 0.1470 - val_accuracy: 0.9754\n",
      "Epoch 82/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0664 - accuracy: 0.9812 - val_loss: 0.1491 - val_accuracy: 0.9702\n",
      "Epoch 83/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0594 - accuracy: 0.9827 - val_loss: 0.1628 - val_accuracy: 0.9726\n",
      "Epoch 84/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0529 - accuracy: 0.9834 - val_loss: 0.1545 - val_accuracy: 0.9714\n",
      "Epoch 85/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.1630 - val_accuracy: 0.9726\n",
      "Epoch 86/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0632 - accuracy: 0.9816 - val_loss: 0.1792 - val_accuracy: 0.9647\n",
      "Epoch 87/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0643 - accuracy: 0.9801 - val_loss: 0.1590 - val_accuracy: 0.9726\n",
      "Epoch 88/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0638 - accuracy: 0.9777 - val_loss: 0.2058 - val_accuracy: 0.9623\n",
      "Epoch 89/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0569 - accuracy: 0.9827 - val_loss: 0.1811 - val_accuracy: 0.9619\n",
      "Epoch 90/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.1402 - val_accuracy: 0.9750\n",
      "Epoch 91/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0572 - accuracy: 0.9814 - val_loss: 0.1722 - val_accuracy: 0.9683\n",
      "Epoch 92/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0603 - accuracy: 0.9823 - val_loss: 0.1676 - val_accuracy: 0.9698\n",
      "Epoch 93/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0712 - accuracy: 0.9810 - val_loss: 0.1536 - val_accuracy: 0.9738\n",
      "Epoch 94/100\n",
      "4575/4575 [==============================] - 13s 3ms/sample - loss: 0.0578 - accuracy: 0.9795 - val_loss: 0.1443 - val_accuracy: 0.9754\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0708 - accuracy: 0.9803 - val_loss: 0.1766 - val_accuracy: 0.9663\n",
      "Epoch 96/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0569 - accuracy: 0.9823 - val_loss: 0.1515 - val_accuracy: 0.9726\n",
      "Epoch 97/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0674 - accuracy: 0.9786 - val_loss: 0.1663 - val_accuracy: 0.9706\n",
      "Epoch 98/100\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0616 - accuracy: 0.9808 - val_loss: 0.1700 - val_accuracy: 0.9742\n",
      "Epoch 99/100\n",
      "4544/4575 [============================>.] - ETA: 0s - loss: 0.0606 - accuracy: 0.9822\n",
      "Reached 97.75% accuracy on test set, so cancelling training!\n",
      "4575/4575 [==============================] - 12s 3ms/sample - loss: 0.0605 - accuracy: 0.9821 - val_loss: 0.1466 - val_accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28b235de708>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_accuracy')>=0.9775):\n",
    "      print(\"\\nReached 97.75% accuracy on test set, so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3),  activation=tf.nn.relu, input_shape=(28, 28, 3)), #padding='SAME', strides=(2, 2),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.7),\n",
    "    tf.keras.layers.Conv2D(64, (3,3),  activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.7),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(62, activation=tf.nn.softmax)\n",
    "\n",
    "])\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(Trainimages, np.array(y_train),validation_data=(Testimages, np.array(y_test)),  epochs=100, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes about training\n",
    "=> 3-3 kernel is superior to others\\\n",
    "\\\n",
    "=> Model with  \n",
    "Conv2D(256) + MaxPolling2D + Dropout(.5) + \\\n",
    "Conv2D(256) + MaxPolling2D + Dropout(.5) + \\\n",
    "Dense(512) + Dense (62)  \\\n",
    "also gives greater than 97.7% accuracy \\\n",
    "\\\n",
    "=> Padding and Strides do not increase the accuracy, but reduces a little bit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
